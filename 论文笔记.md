# 论文笔记
## 搜推融合
- wsdm22，Joint Learning of E-Commerce Search and Recommendation
    - 构造统一的图来解决是否有显式查询的差异，将用户和物品的交互作为边（如果为查询则将word序列作为query，如果为点击则置空）
    - 将GNN过程改写，在对总目标$n_t$的下游节点$n$扩展邻居节点时，同时考虑$n$的父节点$n_p$和子节点$n_n$。
    - 缺点是没有使用序列方法，缺乏对时间戳的进一步利用
- cikm21，User: A Unified Information Search and Recommendation Model Based on Integrated Behavior Sequence
    - 将搜索和推荐中的行为整合到一个异构的行为序列中，具体而言，序列为$\{B_1, B_2, Q_1\{C_1, C_2\}, B_3, ...\}$，其中$B$为浏览点击，$Q$为查询query，$C$为查询后的点击
    - 从整合序列中挖掘用户兴趣
    - 缺点是序列较长，难以处理，以及并未考虑跨场景的方法
- emnlp19，Neural News Recommendation with Heterogeneous User Behavior
    - 利用CNN从新闻标题中学习新闻的表示，利用注意力选择重要词汇
    - 多视图学习框架：从异构行为（如搜索、点击、浏览）中学习用户统一表示，分别对新闻、查询query、查询中的单词建模
    - 目的：利用用户行为增强推荐
- 2022，A Model-Agnostic Casual Learning Framework for Recommendation Using Search Data
    - 提出一个不可知框架
    - 利用因果分析，将搜索行为嵌入为工具变量，用以分解推荐中的原始嵌入向量
- CIKM21，Self-Supervised Learning on User's Spontaneous Behavior for Multi-Scenario Ranking in E-Commerce
    - 对用户自发行为（搜索行为）进行预训练
- WWW2021, Learning a Product Relevance Model from Click-Through Data in E-Commerce
    - 显示与用户意图不匹配
    - 利用用户点击来学习，但是用户点击行为是嘈杂的
    - 利用用户对搜索结果的点击，来判断搜索结果的相关性
    - 通过注意力机制来提取产品和查询信息
- [SIGIR2020, Knowledge Enhanced Personalized Search](https://dl.acm.org/doi/10.1145/3397271.3401089)
    


## in-context learning
- 单开一条，说明一下情况，现在是2023年3月9日，有一个美团的项目申请，不大，但是可以使用大模型，这里试图使用in-context learning，现在提出一个小想法，就是利用大模型作为一个随时取用的知识库，将大模型完全冻结，然后考虑推理过程，由于多步推理类似多层模型，故而堆叠很多层次的prompt核，每个核生成了prompt以后，就交给大模型作表示，然后再将表示送往下一层的prompt核，这样堆叠交替进行，从而进行深度推理。接下来调研相关文献中。
- [A Survey on In-context Learning](https://arxiv.org/abs/2301.00234)
    - 一切的起点，作为2023年1月的综述，以下数篇皆出自这里
- [Complexity-Based Prompting for Multi-Step Reasoning](https://arxiv.org/abs/2210.00720)
    - 预印本，也在做大模型推理
    - 解决的是NLP领域问题，研究的问题类似于求解数学题
    - CoT问题，即chain-of-thought，为大模型提供推理链示例让大模型进行推理
    - 采用复杂的prompt交给语言模型，从而提升推理能力和泛化能力（观察所得）
- [Large Language Models are Zero-Shot Reasoners](https://arxiv.org/abs/2205.11916)
    - 经过实验证明，当对LLM提供CoT时，LLM的效果是好的，即使面对Few-Shot，也有较好表现
    - 但是面对零样本问题，就不尽人意，但如果给它一句“Let's think step by step.”就会好很多。
- [Automatic Chain of Thought Prompting in Large Language Models](https://arxiv.org/abs/2210.03493)
    - 也是CoT问题，这一次设计一个自动的CoT生成器
    - 发现零样本的方法并不好，然后手动标注方法太贵，所以聚类之后选出代表性问题进行启发式生成
- [Measuring and Narrowing the Compositionality Gap in Language Models](https://arxiv.org/abs/2210.03350)
    - 通过自问自答的方式提升大模型推理能力
    - 使用一个多跳推理数据集，比如“贾斯汀比伯出生那年谁赢得了xx比赛冠军？”
    - 目的是解决搜索引擎中的此类问题
    - 方法是在数据集中为一个这种多跳问题构建多个子问题，引导大模型进行理解。
- [Least-to-Most Prompting Enables Complex Reasoning in Large Language Models](https://arxiv.org/abs/2205.10625)
    - 把问题拆成一个一个小问题，这些小问题交给预训练模型回答，每次回答完$q_k$得到答案$a_k$，都把$q_k, a_k$都放到$q_{k+1}$中。
    - 这是一个两阶段问题，第一阶段由LLM将大问题拆成若干小问题，第二阶段迭代求出最终结果。（没涉及什么模型，感觉像一个观察）
- [Iteratively Prompt Pre-trained Language Models for Chain of Thought](https://arxiv.org/abs/2203.08383)
    - 设计一个迭代上下文推理感知器，每次prompter基于$\{q,c_1,..., c_{n-1}\}$生成一个$p_n$，提交给LLM生成$c_n$（可恶这不是和一开始的想法一样嘛）
- 目前推荐中的因果推理工作可以分为以下三类，即针对数据偏差的因果推理推荐算法、针对数据缺失和噪声的因果推理推荐算法以及超越推荐精度的因果推理推荐算法。
- [GPT Understands, Too](https://arxiv.org/abs/2103.10385)
    - 这是一种Pattern-Exploiting Training(PET)，想法是通过构建模板(Pattern)的方式调优BERT类或GPT类的模型，具体而言，**加入补充信息&构建完形填空**，从而提升**小样本/零样本**效果。
    - 这是一个观察：虽然使用这种前缀调优法主要是为了适应小样本，并且节省空间和时间，但是即便在样本充足、开放全部参数调优的情况下，它仍然有优势，可能是因为任务目标和预训练任务更为契合。
    - 





## 可信GNN
- arXiv2022, A Comprehensive Survey on Trustworthy Graph Neural Networks: Privacy, Robustness, Fairness, and Explainability
    - Privacy, Robustness, Fairness, Explainability四个角度较为系统介绍可信GNN
- NIPS2019, Gnnexplainer: Generating explanations for graph neural networks
    - GNN缺乏透明度，是因为它的预测不容易得到人类理解的解释
    - 解释GNN可以增强信任、提高公平性、保护数据隐私、便于使用者纠错
    - 通过构建一个最相关子图的方式解释做出分类的原因
- NIPS2020, Parameterized explainer for graph neural network
    - 之前的工作是对单个分类结果的解释，当解释整个模型的多个结果时性能很差
    - 提出一个高效的对全部分类结果/对图分类结果的解释
    - 利用节点表示和原始图来计算边分布的潜在变量

## 杂
- KDD2018, Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts
- IEEE2020, Scenario-aware and Mutual-based approach for Multi-scenario Recommendation in E-Commerce
- CIKM2021, One Model to Serve All: Star Topology Adaptive Recommender for Multi-Domain CTR Prediction
- CIKM2022, Tiger Transferable Interest Graph Embedding for Domain-Level Zero-Shot Recommendation
- KDD2022, Contrastive Cross-domain Recommendation in Matching
- SIGIR2020，CATN: Cross-Domain Recommendation for Cold-Start Users via Aspect Transfer Network
    - 利用注意力机制提取用户细粒度偏好，迁移到目标域
    - 同时利用用户评论、商品评论和相似用户评论，结合后预测CTR
    - 源域和目标域同时向对面进行迁移
- A Survey for In-context Learning
    - 分为两阶段：一阶段训练模型的ICL能力，二阶段根据任务的演示进行预测
- Personalized Prompts for Sequential Recommendation
    - 利用预训练建模，缓解现实世界中的数据稀疏问题
    - 使用提示调优（Protempt-tuning）来缓解预训练目标和下游目标的差距并减少数据使用量
    - 挑战
        - 如何转换问题？
        - 如何构建适合推荐的提示？
    - 将用户切为warm和cold，分别用来预训练和调优，切分依据是历史序列长度
    - SASRec作为预训练模型，输入为用户点击序列，预测任务是预测用户的下一个点击
    - 第一步：使用MLP基于用户特征生成前缀的提示序列
    - 第二步：进行调优，light版本只调整prompt-tune的参数，快但效果不好；full版本连着预训练模型一起调优，效果upup
    - 加入对比学习元素，把user embedding和行为序列都进行随机mask，并且作对比学习，预防over fitting
    
- SIGIR'23审稿, Domain-Oriented Knowledge Transfer for Cross-Domain Recommendation
    - 利用跨领域知识图谱迁移；设计一种有效的跨域策略
    - 利用类似KGCN的方式进行节点聚合，但是不知为何Eq(1)只讨论了user，没讨论item
    - 设计了一系列采样策略，分为random、target优先、source优先
    - 挖掘兴趣就是先两层MLP，然后用transformer拿下
    - 跨领域知识图谱是拿现有的知识图谱进行合并得到的
    - 怎么没写另外几个模型的参数，怎么用的模型只有两个是近两年的
