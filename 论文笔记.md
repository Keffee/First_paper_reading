# 论文笔记

## 目前的时间日程：
### 超快的话八月半是WSDM截稿，大约十月初是DASFAA和WWW的截稿时间

## 因果相关的多行为推荐
- WWW'22，[A Model-Agnostic Casual Learning Framework for Recommendation Using Search Data](https://arxiv.org/abs/2202.04514)
    - 提出一个不可知框架
    - 利用因果分析，将搜索行为嵌入为工具变量，用以重构推荐中的原始嵌入向量，避免干扰因子的作用
    - 由于搜索引擎的数据是user-query-item-click四元组，所以可以通过数据召回每一个被点击item前的query，然后利用bert等方法将文本转化为向量；对于用户user，则利用其浏览历史的item构建。
- TOIS'23, [Enhancing Recommendation with Search Data in a Causal Learning Manner](https://dl.acm.org/doi/10.1145/3582425)
    - 上面工作的延续，
- arxiv'23，[Zero-shot causal learning](https://arxiv.org/pdf/2301.12292.pdf)（CAML）
    - 本文试图在零样本环境下探究干预因素(intervention)的影响（即新干预对新样本的影响），因此需要将新干预想办法与旧干预对齐
    - CATE: Conditional Average Treatment Effects
    - W:干预特征，X:用户特征
    - 模型包括三个部分：训练单独的元模型以学习CATE，并试图推广到尚未学过的任务上；直接利用intervention的伪结果生成影响；利用大量的离散任务提升效果
    - treated是有intervention的，control是没有的
    - 允许多个W在同一个i中，但是只是将它们加和
    - 优化一个无偏、有噪声的$\tao_i^{\{j\}}$（使用RA-learner方法生成，是一种回归方法，具体不太懂），代表CATE的结果，把这称为伪结果
    - 利用伪结果对对(w,x)分析的模型进行优化
- AAAI'23, [Learning Instrumental Variable from Data Fusion for Treatment Effect Estimation](https://arxiv.org/pdf/2208.10912.pdf)
    - 完全体见此[网址](http://sias.zju.edu.cn/2023/0513/c57510a2756778/page.htm)
- arxiv'23, 综述[Causal Inference for Recommendation: Foundations, Methods and Application](https://arxiv.org/pdf/2301.04016.pdf)


## 大模型与推荐系统
- [A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)
    - 以下内容应该基本来自于该综述
- Large Language Models are Zero-Shot Rankers for Recommender Systems
    - 评测了LLM在推荐系统中的零样本排序能力
    - LLM能根据历史交互实现个性化排序，但是很难感知到用户历史交互的序列关系
    - 零样本能力很好，但是存在position bias和popularity bias
- Chat-REC: Towards Interactive and Explainable LLMs-Augmented Recommender System
    - 构建对话式推荐系统，在这里，LLM能够对用户推荐并且提供个性化解释
- Rethinking the Evaluation for Conversational Recommendation in the Era of Large Language Models
    - 改善对话式推荐的评测方式，使其更加关注于对话推荐系统的交互能力
    - 使用LLM用户模拟器来测试LLM的对话推荐能力
- Zero-Shot Next-Item Recommendation using Large Pretrained Language Models
    - 评测零样本设定下LLM在下一个物品预测任务下的能力。
    - 使用外部模块生成候选物品，然后分别提示LLM：提取用户偏好、选择代表性历史交互物品、推荐并排序前10
    - 零样本能力极好
- Is ChatGPT a Good Recommender? A Preliminary Study
    - 在评分预测、序列推荐、直接推荐、解释生成和评论摘要五个任务下测试了chatgpt性能
    - 发现评分预测、解释生成和评论摘要任务表现较好
    - 从人类角度，LLM生成的解释和摘要更清晰符合逻辑（但是传统评测指标下不好）
- Uncovering ChatGPT’s Capabilities in Recommender Systems
    - 分析chatgpt在point-wise, pair-wise, list-wise的排序能力
    - list-wise具有最高性价比。
    - 能够缓解冷启动问题、提升可解释效果
- Do LLMs Understand User Preferences? Evaluating LLMs On User Rating Prediction
    - 专门评测LLM在评分预测任务上的表现
    - 冷启动下模型参数增加效果更好
    - 零样本设定下，LLM效果远差于完整数据上的传统模型
    - LLM的data efficiency更好，小数据可以取得优于传统模型的结果
- Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation
    - LLM存在一定的社会偏见
    - 提出公平性benchmark，发现LLM可能产生不公平的推荐
- Generative Recommendation: Towards Next-generation Recommender Paradigm
    - 传统方法是从物品集中检索合适的物品，但是已有物品集不一定符合，用户反馈（如点击）很低效
    - 提出生成式推荐范式，基于用户指令和传统反馈，依据AI生成方法重定制已有物品
- GPT4Rec: A Generative Framework for Personalized Recommendation and User Interests Interpretation
    - 传统ID判别式方法导致无法利用物品内容信息和NLP模型的语言建模能力，无法解释用户兴趣，无法适配商品的增加
    - 基于历史交互物品和对应标题，用gpt2生成假设的搜索查询，引入搜索引擎来检索
- A First Look at LLM-Powered Generative News Recommendation
    - 传统新闻推荐面临冷启动、用户画像建模、新闻内容理解问题
    - 利用可获得数据来构建提示，从而激发LLM基于通用知识产生相关信息
- Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach
    - 传统ID推荐难泛化、用户的参与比较被动
    - 用户历史+评论构成指令，从而微调大模型以推荐
- TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation
    - LLM的训练任务和推荐任务的不一致导致了次优结果
    - 指令微调阶段之后，进行推荐微调，将推荐数据化为指令微调格式，利用历史交互判断是否喜欢目标商品


## 搜推融合
- wsdm22，[Joint Learning of E-Commerce Search and Recommendation](https://dl.acm.org/doi/abs/10.1145/3488560.3498414)
    - 构造统一的图来解决是否有显式查询的差异，将用户和物品的交互作为边（如果为查询则将word序列作为query，如果为点击则置空）
    - 将GNN过程改写，在对总目标$n_t$的下游节点$n$扩展邻居节点时，同时考虑$n$的父节点$n_p$和子节点$n_n$，并且融合两个节点之间的查询关系$q$.
    - 缺点是没有使用序列方法，缺乏对时间戳的进一步利用
- cikm21，[User: A Unified Information Search and Recommendation Model Based on Integrated Behavior Sequence](https://arxiv.org/abs/2109.15012)
    - 将搜索和推荐中的行为整合到一个异构的行为序列中，具体而言，序列为$\{B_1, B_2, Q_1\{C_1, C_2\}, B_3, ...\}$，其中$B$为浏览点击，$Q$为查询query，$C$为查询后的点击
    - 从整合序列中挖掘用户兴趣
    - 缺点是序列较长，难以处理，以及并未考虑跨场景的方法
    - 流程分为四块：
        - Text Encoder：将文本转换为embedding，由于这一部分可替方法很多，所以略过
        - Session Encoder：
            - 最后一步的预测环节embedding，如果是查询就把query给编码了，否则使用user embedding
            - 对于search的embedding，需要同时考虑search query和所有browsed articles（合在一起），二者经过两层神经网络结合之后输出（对于待排序的文档也可以这样做）
        - History Encoder：利用最后一个session的/总的最后一个输出作为对应的待预测问题的embedding
        - Unified Task Framework：同时计算短期、长期的交叉相似性（这样一来就是2*2=4种相似性），加上利用KNRM计算的搜索-文档相似性和基于相似性的特征，共六种，利用MLP合成。
- emnlp19，Neural News Recommendation with Heterogeneous User Behavior
    - 利用CNN从新闻标题中学习新闻的表示，利用注意力选择重要词汇
    - 多视图学习框架：从异构行为（如搜索、点击、浏览）中学习用户统一表示，分别对新闻、查询query、查询中的单词建模
    - 目的：利用用户行为增强推荐
- CIKM21，Self-Supervised Learning on User's Spontaneous Behavior for Multi-Scenario Ranking in E-Commerce
    - 对用户自发行为（搜索行为）进行预训练
- WWW2021, [Learning a Product Relevance Model from Click-Through Data in E-Commerce](https://arxiv.org/abs/2102.07098v1)
    - 显示与用户意图不匹配
    - 利用用户点击来学习，但是用户点击行为是嘈杂的
    - 利用用户对搜索结果的点击，来判断搜索结果的相关性
    - 通过注意力机制来提取产品和查询信息
- Pre-Print2022, Amazon, [Efficient and effective training of language and graph neural network models](https://arxiv.org/abs/2206.10781)
    - 基于GNN和BERT联合微调，但是或许可以考虑此后使用prompt相关方法改良？总之还是往下看
    - 在本文中，是这样一张图：节点表示query和item，边表示点击/购买（这种数据形式为[Amazon KDD Cup 22'](https://www.aicrowd.com/challenges/esci-challenge-for-improving-product-search)，认为节点包含短文本信息，而边不包含（当然也有别的数据集，因为本文算一个观察，讨论的是通用的方法），本文正是要探寻把节点文本嵌入语言模型的方法
    - 三个预测任务：预测边的存在，预测节点分类，预测边的类型
    - 直接使用语言模型的两个问题：嵌入不准确、嵌入效率低
        - 嵌入不准确问题：使用对比学习对LM进行微调，然后冻住LM对gnn进行预热
        - 嵌入效率低问题：随机小批量采样优化LM，剩余时间冻住LM；提前进行整体的文本嵌入并缓存，代价是准确性降低；联合负采样，重用负的边的例子；
    - 实验配置：
        - GNN：同质图：GraphSAGE，异构图：RGCN
        - LM：BERT，用对比学习train一下
    - 实验结果：
        - 节点分类：普通MLP+finetune和GNN+无finetune效果相当，说明初始的BERT不适合图结构；对BERT作对比学习也能显著提升效果
        - 链路预测：BERT对比学习带来了及其显著的提升；热启动带来了相当的优势；此外，热启动速度很快
        - 链路分类：首先，GNN对于链路分类效果的确提高，但是使用调过的BERT，却导致了效果下降，这是一个观察。
        - 推荐效果：在私有数据集进行训练，相当于只考虑链路分类中的E，结果效果好了，现在看可能是因为amazon比赛数据集的问题
- SIGIR '23, [When Search Meets Recommendation: Learning Disentangled Search Representation for Recommendation](https://arxiv.org/pdf/2305.10822.pdf)
    - 对点击和搜索都进行相似和不相似的切分
- CIKM '22, [Query-Aware Sequential Recommendation](https://dl.acm.org/doi/10.1145/3511808.3557677)

- SIGIR2020, [Knowledge Enhanced Personalized Search](https://dl.acm.org/doi/10.1145/3397271.3401089)
    - 你先别急，这是做知识图谱的，先往后放放

- Keyword-Based Knowledge Graph Exploration Based on Quadratic Group Steiner Trees（在复杂知识图谱上的搜索）
- FedPS: A Privacy Protection Enhanced Personalized Search Framework（个性化搜索中的隐私泄露问题）
- Attentive Long Short-Term Preference Modeling for 5. Personalized Product Search（用长短期记忆网络辅助个性化搜索）
- Embedding-based Retrieval in Facebook Search（facebook上的个性化搜索）
- Modeling User Behavior with Graph Convolution for Personalized Product Search（对用户连续行为图进行建模，挖掘用户偏好（可这和搜推有什么关系呢？）
- CL4CTR: A Contrastive Learning Framework for CTR Prediction（进行特征表示工程）
- Efficient and effective training of language and graph neural network models（GNN结合大规模语言模型做推荐，先看看吧）
- ReprBERT: Distilling BERT to an Efficient Representation-Based Relevance Model for E-Commerce（接下来的四篇都看过了，都旨在解决搜索结果与用户意图不匹配的问题）
- Graph-based Weakly Supervised Framework for Semantic Relevance Learning in E-commerce
- Learning a Product Relevance Model from Click-Through Data in E-Commerce
- Weakly Supervised Co-Training of Query Rewriting and Semantic Matching for e-Commerce

- 师兄的代码阅读
#### 相关的数据集：
- [ZhihuRec](https://github.com/THUIR/ZhihuRec-Dataset)数据集，有100M，20M，1M三档，包括了用户搜索、点击、阅读的行为，以及问题、答案的特征



## in-context learning
- 单开一条，说明一下情况，现在是2023年3月9日，有一个美团的项目申请，不大，但是可以使用大模型，这里试图使用in-context learning，现在提出一个小想法，就是利用大模型作为一个随时取用的知识库，将大模型完全冻结，然后考虑推理过程，由于多步推理类似多层模型，故而堆叠很多层次的prompt核，每个核生成了prompt以后，就交给大模型作表示，然后再将表示送往下一层的prompt核，这样堆叠交替进行，从而进行深度推理。接下来调研相关文献中。
- [A Survey on In-context Learning](https://arxiv.org/abs/2301.00234)
    - 一切的起点，作为2023年1月的综述，以下数篇皆出自这里
- [Complexity-Based Prompting for Multi-Step Reasoning](https://arxiv.org/abs/2210.00720)
    - 预印本，也在做大模型推理
    - 解决的是NLP领域问题，研究的问题类似于求解数学题
    - CoT问题，即chain-of-thought，为大模型提供推理链示例让大模型进行推理
    - 采用复杂的prompt交给语言模型，从而提升推理能力和泛化能力（观察所得）
- [Large Language Models are Zero-Shot Reasoners](https://arxiv.org/abs/2205.11916)
    - 经过实验证明，当对LLM提供CoT时，LLM的效果是好的，即使面对Few-Shot，也有较好表现
    - 但是面对零样本问题，就不尽人意，但如果给它一句“Let's think step by step.”就会好很多。
- [Automatic Chain of Thought Prompting in Large Language Models](https://arxiv.org/abs/2210.03493)
    - 也是CoT问题，这一次设计一个自动的CoT生成器
    - 发现零样本的方法并不好，然后手动标注方法太贵，所以聚类之后选出代表性问题进行启发式生成
- [Measuring and Narrowing the Compositionality Gap in Language Models](https://arxiv.org/abs/2210.03350)
    - 通过自问自答的方式提升大模型推理能力
    - 使用一个多跳推理数据集，比如“贾斯汀比伯出生那年谁赢得了xx比赛冠军？”
    - 目的是解决搜索引擎中的此类问题
    - 方法是在数据集中为一个这种多跳问题构建多个子问题，引导大模型进行理解。
- [Least-to-Most Prompting Enables Complex Reasoning in Large Language Models](https://arxiv.org/abs/2205.10625)
    - 把问题拆成一个一个小问题，这些小问题交给预训练模型回答，每次回答完$q_k$得到答案$a_k$，都把$q_k, a_k$都放到$q_{k+1}$中。
    - 这是一个两阶段问题，第一阶段由LLM将大问题拆成若干小问题，第二阶段迭代求出最终结果。（没涉及什么模型，感觉像一个观察）
- [Iteratively Prompt Pre-trained Language Models for Chain of Thought](https://arxiv.org/abs/2203.08383)
    - 设计一个迭代上下文推理感知器，每次prompter基于$\{q,c_1,..., c_{n-1}\}$生成一个$p_n$，提交给LLM生成$c_n$（可恶这不是和一开始的想法一样嘛）
- **目前推荐中的因果推理工作可以分为以下三类，即针对数据偏差的因果推理推荐算法、针对数据缺失和噪声的因果推理推荐算法以及超越推荐精度的因果推理推荐算法。**
- [GPT Understands, Too](https://arxiv.org/abs/2103.10385)
    - 这是一种Pattern-Exploiting Training(PET)，想法是通过构建模板(Pattern)的方式调优BERT类或GPT类的模型，具体而言，**加入补充信息&构建完形填空**，从而提升**小样本/零样本**效果。
    - 这是一个观察：虽然使用这种前缀调优法主要是为了适应小样本，并且节省空间和时间，但是即便在样本充足、开放全部参数调优的情况下，它仍然有优势，可能是因为任务目标和预训练任务更为契合。
    - 
- [A Survey of Graph Prompting Methods: Techniques, Applications, and Challenges](https://arxiv.org/abs/2303.07275)
    - 这一切发生的太快了，这么快已经产生了图的prompt learning综述
    - prompt生成大体分为3种：
        - 手动提示设计：基于下游任务的特定人类知识创建模板
        - 离散提示设计：用输入样本的个性化邻域和边填充模板
        - 连续提示设计：根据模板的表示向量生成模板

## 可信GNN
- arXiv2022, A Comprehensive Survey on Trustworthy Graph Neural Networks: Privacy, Robustness, Fairness, and Explainability
    - Privacy, Robustness, Fairness, Explainability四个角度较为系统介绍可信GNN
- NIPS2019, Gnnexplainer: Generating explanations for graph neural networks
    - GNN缺乏透明度，是因为它的预测不容易得到人类理解的解释
    - 解释GNN可以增强信任、提高公平性、保护数据隐私、便于使用者纠错
    - 通过构建一个最相关子图的方式解释做出分类的原因
- NIPS2020, Parameterized explainer for graph neural network
    - 之前的工作是对单个分类结果的解释，当解释整个模型的多个结果时性能很差
    - 提出一个高效的对全部分类结果/对图分类结果的解释
    - 利用节点表示和原始图来计算边分布的潜在变量

## 杂
- KDD2018, Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts
- IEEE2020, Scenario-aware and Mutual-based approach for Multi-scenario Recommendation in E-Commerce
- CIKM2021, One Model to Serve All: Star Topology Adaptive Recommender for Multi-Domain CTR Prediction
- CIKM2022, [Tiger Transferable Interest Graph Embedding for Domain-Level Zero-Shot Recommendation](https://dl.acm.org/doi/abs/10.1145/3511808.3557472)
- KDD2022, Contrastive Cross-domain Recommendation in Matching
- SIGIR2020，CATN: Cross-Domain Recommendation for Cold-Start Users via Aspect Transfer Network
    - 利用注意力机制提取用户细粒度偏好，迁移到目标域
    - 同时利用用户评论、商品评论和相似用户评论，结合后预测CTR
    - 源域和目标域同时向对面进行迁移
- A Survey for In-context Learning
    - 分为两阶段：一阶段训练模型的ICL能力，二阶段根据任务的演示进行预测
- [Personalized Prompts for Sequential Recommendation](https://arxiv.org/abs/2205.09666)
    - 利用预训练建模，缓解现实世界中的数据稀疏问题
    - 使用提示调优（Protempt-tuning）来缓解预训练目标和下游目标的差距并减少数据使用量
    - 挑战
        - 如何转换问题？
        - 如何构建适合推荐的提示？
    - 将用户切为warm和cold，分别用来预训练和调优，切分依据是历史序列长度
    - SASRec作为预训练模型，输入为用户点击序列，预测任务是预测用户的下一个点击
    - 第一步：使用MLP基于用户特征生成前缀的提示序列
    - 第二步：进行调优，light版本只调整prompt-tune的参数，快但效果不好；full版本连着预训练模型一起调优，效果upup
    - 加入对比学习元素，把user embedding和行为序列都进行随机mask，并且作对比学习，预防over fitting
- Virtual Node Tuning for Few-shot Node Classification(师兄审的一篇稿)
    - 对于预训练过的graph transformer，利用在嵌入空间生成虚拟节点的方式进行软提示
- Generative Recommendation: Towards Next-generation Recommender Paradigm
    - 在结合用户历史交互序列（即用户偏好）的情况下生成、处理视频流的模型，是一个生成式模型（视频版chatgpt？）
- ICLR'23, [LightGCL: Simple Yet Effective Graph Contrastive Learning for Recommendation](https://arxiv.org/abs/2302.08191)
    - 当前存在的问题：
        - 随机的数据增强可能导致数据结构的大改变
        - 现有的对比学习方法与数据分布强相关，易受噪声干扰
        - 存在过平滑问题
    - 采用奇异值分解的方式重构图像，借用图像去噪的一个观点，只保留前$q$大的奇异值，再利用其重构邻接矩阵
    - 目标：
        - 减小过平滑/过拟合
        - 避免图形结构改变
        - 快速
- ICLR'23, [Multi-Behavior Dynamic Contrastive Learning for Recommendation](https://openreview.net/pdf?id=ykOpK9O5qYv)
    - 学习用户多行为的异质图
    - 利用对比学习建模用户的细粒度长期偏好
- KDD'22, [Multi-Behavior Hypergraph-Enhanced Transformer for Sequential Recommendation](https://arxiv.org/abs/2207.05584)
    - 多行为超图增强的transformer框架
- WWW'23, [Denoising and Prompt-Tuning for Multi-Behavior Recommendation](https://arxiv.org/abs/2302.05862)
    - 多行为建模，考虑点击、加购和购买三者之间的联系
    - 比之过去的多行为建模方法，此方法旨在消除多行为数据中的噪声影响
    - 定义$K$张图，$G^a_{ui}$代表辅助交互，$G^t_{ui}$代表目标交互，希望输入一个$G$，能返回去噪的$G'^a+G^t$
    - 利用Jaccord系数求两个用户的相关性，大于0则在uu图连一条边（这看上去是一种生成uu图的方法）（当然，出处是21年的一篇aaai）
    - 利用用户历史交互，只要用户历史序列点过a再点b，就把ab连上
    - embedding层为每个u、每个i、每个行为都设计一个embedding矩阵
    - aggregation层
        - uu图（无向图）使用GCN
        - ii图（有向图）使用GAT，入图和出图分开
        - ui图使用lightGCN
        - 经典用门聚合
        - 利用embedding重建$G_{ui}$，然后算损失，从属于一个观点：噪声更难以被重建出来
- WWW'23, [Compressed Interaction Graph based Framework for Multi-behavior Recommendation](https://arxiv.org/abs/2303.02418)（华为郭老师项目）
    - 针对多行为推荐问题，使用一种多专家网络+GCN的方式，捕获实例级高阶关系
    - 行为作为“特征”，提供了多种显式交互；行为作为“标签”，可以缓解与隐藏梯度的冲突

- SIGIR'23审稿, Domain-Oriented Knowledge Transfer for Cross-Domain Recommendation
    - 利用跨领域知识图谱迁移；设计一种有效的跨域策略
    - 利用类似KGCN的方式进行节点聚合，但是不知为何Eq(1)只讨论了user，没讨论item
    - 设计了一系列采样策略，分为random、target优先、source优先
    - 挖掘兴趣就是先两层MLP，然后用transformer拿下
    - 跨领域知识图谱是拿现有的知识图谱进行合并得到的
    - 怎么没写另外几个模型的参数，怎么用的模型只有两个是近两年的
- KDD'23审稿, IncMSR: An Incremental Learning Approach for Multi-Scenario Recommendation
    - 用多场景数据train一个统一模型服务所有场景，解决多场景多数据效率问题和数据在时间上的分布关系的问题。
    - 方法：量化场景、时间和时间-场景的pair-wise距离，利用增量模型学习，最后用度量学习（对比学习）进行统一。
    - 等于在处理时间序列？先输入一段序列，然后逐时间步用后续序列来更新模型（增量模型方法）
    - 出现语法错误——把MMoE写成了HMoE（related work部分），没有说明$N_{t,d}$是什么
    - 整体框架上：
        - 基于度量学习想法，学习一个$f$将点映射到表示空间
        - 最小化共享层的场景间距离和跨时间距离，最大化场景特定层的场景间距离和跨场景跨时间距离
        - 预测就使用交叉熵损失
    - 回答三个问题：
        - 模型性能如何——经过比较，优于现有MSR模型
        - 与现有MSR兼容度如何
        - 设计的三种特殊的传递有没有意义
- WSDM22'，[Heterogeneous Graph Contrastive Learning for Recommendation](https://arxiv.org/abs/2303.00995)
    - 异质图的图神经网络
    - 在有元网络的情况下辅助对比学习
    - 简而言之，利用三个图：u-u，u-i，i-i，以u举例，基于单独的u、基于u-i、基于u-u，均生成表征，在有联系的u-u和没联系的u-u之间；在有联系的u-i和没联系的u-i之间 作对比学习。


## 书
- [A Cookbook of Self-Supervised Learning](https://arxiv.org/abs/2304.12210)
- [Science Research Writing for non-native English Speakers](D:\OneDrive - USTC\学习\学习资料\Glasman-Deal - 2010 - Science research writing for non-native speakers o.pdf)