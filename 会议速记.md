<!-- 接下来的内容是各个开会、讨论的记录 -->
#### 20230317 美团进度
- 缺少公开数据集
- \*没想到过去的实习生，也不完全跟着实验走，也要自己做research
- 想法：右边是搜索，左边两个行为数据是行为数据（推荐），
- 最近去调研一下最近的搜推融合方法（包括冠琪师兄发在群里的内容）
- 论文列表：
    1. Knowledge Enhanced Personalized Search（知识图谱）
    1. Keyword-Based Knowledge Graph Exploration Based on Quadratic Group Steiner Trees（在复杂知识图谱上的搜索）
    1. FedPS: A Privacy Protection Enhanced Personalized Search Framework（个性化搜索中的隐私泄露问题）
    1. Attentive Long Short-Term Preference Modeling for 5. Personalized Product Search（用长短期记忆网络辅助个性化搜索）
    1. Embedding-based Retrieval in Facebook Search（facebook上的个性化搜索）
    1. Modeling User Behavior with Graph Convolution for Personalized Product Search（对用户连续行为图进行建模，挖掘用户偏好（可这和搜推有什么关系呢？）
    1. CL4CTR: A Contrastive Learning Framework for CTR Prediction（进行特征表示工程）
    1. Efficient and effective training of language and graph neural network models（GNN结合大规模语言模型做推荐，先看看吧）
    1. ReprBERT: Distilling BERT to an Efficient Representation-Based Relevance Model for E-Commerce（接下来的四篇都看过了，都旨在解决搜索结果与用户意图不匹配的问题）
    1. Graph-based Weakly Supervised Framework for Semantic Relevance Learning in E-commerce
    1. Learning a Product Relevance Model from Click-Through Data in E-Commerce
    1. Weakly Supervised Co-Training of Query Rewriting and Semantic Matching for e-Commerce

#### 20230324 组会
- 回去看看instructive few-shot的那篇
- 回去看看tiger
- 两篇复现一下
- 研究一下冠琪师兄的蒸馏方法，看看和transformer+gnn有什么关系
- autodl——线上服务器

#### 20230407 组会
- 目前师兄都在跑代码，尝试复现各自的论文（并且调试）
- 一种思路的转变->转向生成式网络

#### 20230411 讨论
- 思考搜推融合能不能继续下去
- 思考prompt方法能不能融进来，比如永强师兄的框架能不能直接把prompt部分改成输入搜索query的方式

#### 20230418 会议记录
-（回去看一下HGCL与其他人的对比，看看别人的NDCG是不是真有那么高）（此条删除）
- 尹铭佳
    - 工作规划
        - 使用预训练的多行为长序列建模
            - 图增强的序列推荐
            - 长序列问题优化效率问题
            - 多行为长序列问题
    - 已有工作
        - [SRGNN](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1811.00855), [GCSAN](https://www.ijcai.org/Proceedings/2019/0547.pdf), [GCEGNN](https://dl.acm.org/doi/pdf/10.1145/3397271.3401142)
    - 已有实验结果：
        - 数据集：ML-M, Amazon-beauty, Diginetica, Gowalla
        - 模型：GRU4Rec, SASRec(BCE), SRGNN, GCSAN, GCEGNN
        - SASRec+图对比学习：对于稀疏数据集有着较好提升，但是对稠密矩阵的效果与单纯使用SASRec无明显提升
            - **提问**：取了几个负样本？**回答**：只用了一个
        - SASRec+DirectAU: 在稀疏数据集上产生了较大提升，MF+Di的效果远小于SASRec+DirectAU，可能是因为需要引入更复杂的模型才能支持
            - **提问**：是否应该增加采样，因为现在此领域已经有很多相关结论，应当尝试更多负样本的情况
- 徐翔
    - 超长序列召回：
        - [阿里SIM](https://arxiv.org/pdf/2006.05639.pdf)，soft search效果更好，但是效率较差，因此使用hard search，效果并没有差很多，但是效率好了，可以正常上线
        - [华为UBR](https://arxiv.org/pdf/2005.14171.pdf)
        - [阿里ETA(End-to-End User Behavior Retrieval)](https://arxiv.org/abs/2108.04468)，这是一个CTR模型，更新频率更高，训练/推理成本更低，端到端，
        - [美团SDIM(Sampling-based-Deep Interest Modeling)](https://arxiv.org/pdf/2205.10249.pdf)，使用哈希指纹，在提高AUC的同时也达到了非常高的效率
        - [ADFM(Adversarial Filtering Modeling on Long-term User Behavior Sequences for Click-Through Rate Prediction)](https://arxiv.org/abs/2204.11587)，
            - **提问**：对这样的长序列，是如何处理里面的每个item的？
            **回答**：聚类处理用户的behavior，去除冗余item；
            - **提问**：BSU框架中为何先进行分桶后还要再对user behavior重新top-k分组？这样的处理有意义吗？
            **回答**：留待之后详细研究
        - [快手TWIN: TWo-stage Interest Network for Lifelong User Behavior Modeling in CTR Prediction at Kuaishou](https://arxiv.org/pdf/2302.02352.pdf)，解决目标不一致问题
        - Efficient Dense Retrieval
- 郭威
    - 长序列、多行为进展：
        - 端到端：
            - 长序列：[UBR](https://arxiv.org/pdf/2005.14171.pdf)、[SIM]((https://arxiv.org/pdf/2006.05639.pdf))、[ETA](https://arxiv.org/abs/2108.04468)、[SDIM](https://arxiv.org/pdf/2205.10249.pdf)、ETA+ 
            - 多行为：MBSTR，HPMR
        - **提问**：目前端到端效果如何？
        **回答**：沿着逐步开发的路线，UBR->SIM->ETA，发现端到端的ETA效果会更好一些，更能捕捉全部item的特征。
        - 预训练：word2vec，Transformer，GNN；需要一些新颖的东西来进行提升
        - 下游如何微调

#### 20230425 旁听北京航天局参观实验室
- 北京航天自动控制研究所简介
    - 控制航天运载工具的运行之类的
    - 宇航智能控制技术全国重点实验室
        - 高速飞行的制导控制方法：飞得稳，投得准
        - 精确制导：最末端的制导
        - 光学制导：合作下，非合作下、对抗下
        - 控制系统一体化：设备轻小型、国产化、全自主
        - 快速发射

#### 20230505 组会
- 看看每年的best paper，提升提升？

#### 20230510 组会
- query到click有一个噪声变量，铭佳师兄有一篇就是这个方法，
- 17号把所有结果都跑通
- lightgcn，bpr
- 一个问题：目前的负采样由于负采样时采到正样本的概率很低，故而没有考虑去除负采样中的正样本的操作（因为太慢了），但是最后表述的时候应该要注意一下

#### 20230524 组会
- 看看ICLR吧，比较不水（WWW, KDD, CVPR）
- 日后投稿组内要先过一遍
- 以后读一下因果x多行为（如果可能的话看一看CoT）
- 现在集中在可信上：可解释、鲁棒、安全

### 20230614 组会
- 所有人40分钟快速过一下个人工作
- 我跟永强师兄一组，一共20分钟，轮流进行：一个人详细讲一个人少讲
- 然后talk的那个人再讲40分钟

### 20230616 讨论本子
- 未来还是数据的问题，缺数据就没办法
- 模型架构都基本一样，最关键的还是数据的配比+清洗等
- 格式完全仿照2号word写，思路可以看看pdf

### 20230619 short review
- 看一看ID替代的gpt embedding

### 20230621 组会
- 去看一看cvpr、acl的预训练的、去噪的、多行为的文章，现在阅读量太少了

### 20230626 short review
- 以后也要调研prompt learning相关的论文（prompt+因果+去噪+多行为）

### 20230628 自监督学习分享
- BYOL，用平均值作teacher，单view作student，从而进行自监督

### 20230703 short review
- 可以看一些OOD论文来跟去噪、多行为结合
- 看一看libo的主页
- 这周就先梳理去噪/OOD的文章

### 20230711 深夜讨论多行为是什么
- 目标：用户行为建模的survey
- 问题：用户行为建模和序列推荐的区别在哪里
- 如何切分**多行为**建模
（理一下每个问题的假设）（弄清楚问题和假设之后才考虑方法）
    - 预训练、微调（甚至把这个单独做一个问题点）
    - 多类型的异质融合
    - 多类型的泛化
    - 单任务vs多任务
        - 单任务：负迁移（去偏、去噪）、行为关系建模、鲁棒性
        - 多任务：任务平衡优化、任务设计、效率问题
    - （跨域vs单域）

——先去看华为survey里面提到的文章，然后再去看近期的论文，进老师的系统看看最新的文章
- 跨场景算不算多行为？
- 一到两个礼拜讨论出结果

### 20230712 华为项目讨论
- 威哥：
    - 多行为结合稀疏用户序列长度扩充；多行为预训练和微调
    - LLM：长序列+多行为
- liuyong：
    - 过去的长序列建模建立在传统推荐场景，现在能不能把对话式交互看作长序列
    - 现有的长对话序列问题比较粗糙，可以做...吗？
    - 在对话历史中进行信息检索；所以在长序列问题不仅仅局限在推荐场景，但是实际上可以继续考虑对话场景
    - 检索不一定那么准确，所以大模型需要很强（检索部分提升效率，大模型部分进行修正）
- 威哥：
    - 大语言模型放到预训练来做（大模型通用知识和小模型垂域知识联合学习）
- 现在的合作项目框架：
    - 长序列：多个场景已经打通基本项目，SDIM尝试，目前长度100，在向200-1000尝试
    - 多行为：内部不同业务域数据相互打通（音乐、视频、浏览器），拿到几十个跨域的不同行为，embedding后给到下游任务（在target domain，主要是广告）（目前的ID还是全部不同）
    - 一个想法：将文本信息利用大模型融合到item embedding中，从而便于跨域
- 接下来想做的方向：
    - 长序列：召回方式、召回粒度、召回多样性、自适应召回长度

### 20230719 华为项目讨论
- 预训练的一个问题，预训练数据和finetune数据分布可能会很不一样
- 我们想解决的问题：**跨域推荐**！通过目前已有的多个域数据来增强目标域的效果
- 数据形式：纯ID序列
- 现有的路线：
    - 预训练形式：计算通用embedding（以及如何处理embedding）（以及如何更改embedding生成模型）
    - KG transfer和LLM transfer
    - 更倾向于使用CTR上的方法
    - 迁移形式：尝试利用多域信息进行向目标的迁移

### 20230724 short review
- 这周总结出来跨域序列推荐的论文
- 生成式序列...是什么？和跨域有什么关系？
- 老师最近打算自己做个工作，需要同学帮忙跑实验（

### 20230726 华为项目讨论
- 跟康博约个时间讨论大语言模型接进跨域推荐（利用文本辅助信息迁移）
- 继续调研CIKM今年的投稿文章中跨域序列推荐文章

### 20230727 和师兄关于大模型偏好迁移的讨论
- 皓哥：借助大模型探索物品ID之间的关联性
- 康博：文本关联性easy，但是对item之间关联性有点困难
- 康博：大模型学习ID之间结构的目的是什么呢，用大模型会更好吗？
- 皓哥：希望大模型能学到结构知识
- 康博：直接用大模型做推荐，可以，但是大模型学不到结构化知识，从这个角度上讲...采一些子结构，当成token来做embedding，可能可以？预训练模型究竟怎么和图进行结合呢？之前有工作是直接把所有文本信息放进去
- 现在可以做：深层次的语义理解；结构的transfer，可以用structure token，或者用路径的方式输入大模型之中。根本上来说就是语言与结构进行语义对齐
- 核心目标：怎么学item的予以关系来建模item关联；怎么把item之间的结构关系和文本语义信息通过大模型来建立相似度关联性
- 观其师兄之前做了一个任务，看看能不能把这个思想用在大模型之中
- 也可以看一些最近的图上的LLM，以及多模态大模型（如何把视觉信息输入语言模型）（理解成语义模态和结构模态）（先了解一下思路）
- [链接1](https://mp.weixin.qq.com/s/dQPbNg01aAbRIJt2WdBEgw) [链接2](https://zhuanlan.zhihu.com/p/622220960)
- 可用数据集：Amazon，MDB，arXiv（手动处理量大）
- 有问题问问康博，这周先把这方面文章看一下，代码方面找康博，prompt方面问问永强师兄
- 如何得到对齐的structure embedding
- 对于路径挖掘的代码已经有了，主要关心的是如何得到structure embedding
- 路径不能错，先通过复现部分跨域方法（基于知识图谱的等），打通pipeline，再将大模型替换进去

### 20230728 帮忙写陈老师军工本子
- 第一点：如何处理多源异构数据？多源异构数据融合技术
    - 数据清洗与预处理
    - 多源数据深度表征技术
    - 多源知识实体抽取技术
    - 多源知识实体对齐技术
    - 多源知识体系构建技术
    - 跨模态知识迁移技术
- 第二点：有哪些大数据分析技术方法？J需能源大数据分析技术（维博师兄）
    - 图像处理技术
    - 语音处理技术
    - 文本处理技术
    - 视频处理技术
    - 多模态处理技术
    - **多模态知识图谱技术（和下面分成两块，但是都作为一个大点）**
    **多模态推理技术（多模态融合除去知识图谱）**
- 我们写一个**开题报告**，不像申请书，更像技术报告：主要写研究目的（一页左右？）(motivation)、相关情况分析(related work)、研究内容与技术路线、研究进度与成果形式
- 字数要求：每个点1w字左右，每个同学2k字就行
- ddl是8.10，一周写完就好
- 要写之前先列一下点，给老师看看，确认以后再写
- 对于分配到自己的课题，要写的是国内外研究现状+主要研究内容和技术路线related work差不多700-800字，然后1500字左右的研究内容和技术路线，研究内容和技术路线分开，模仿7J
- 写general一点，网上找资料也行（但是别重），别太domain了，还是要前沿一点的
- 周末先构思一下，这个大点里面最好再分3个左右小点
- 周末出大纲，周一开始写，周五前能有初稿

### 20230802 华为组会
- 现在考虑将item文本信息和序列结构信息输入大模型，具体而言，将用户作为起始，接下来在序列里采样，输入采到的文本和结构信息
- 看一看赵鑫的文章，先复现出来

### 20230807 short review
- 补几个prompt的基准实验
- 

### 20230807 跟师兄讨论
- 我们是多行为多任务，把四个行为的预测角度战胜多任务
- 单目标需要多任务重新训，多任务需要
- 不提sasrec
- 我们想提取共现知识的提取和高效的迁移，但是现在想要解决多任务还没有用预训练+微调范式的，我们认为这是因为它们难以根据下游任务进行微调（未解耦，但我们使用了prompt，达成了完全解耦），于是我们取代了MMOE，更加简单高效
- 我们解决的是多任务问题，目前只能建很多个单任务或者一个多任务模型，但是前者效率低，多任务难以加入新任务；加上多任务有效果跷跷板问题。之前没能做是因为ID没有语义，但是我们解决了

### 20230808 讨论AAAI
- related work，prompt learning in recommendation（看看arxiv上有没有新的，把审稿意见那几篇也拿进来），预训练+微调的baseline快速调研
- 调研矢量图画法

### 20230810 讨论
- 想做的是多行为预训练＋微调的事
- 如何在预训练和微调阶段如何考虑多行为序列推荐的问题，讲传统序列推荐方法解决不了我们问题的困难点在哪
- 预训练一个contribution，微调一个contribution
- related work
    - 序列推荐-多行为-预训练放在多行为里面，有一部分工作关注多行为里的预训练问题
    - prompt learning
- baseline
    - 为了公平，其他人可以把多行为拼一拼
    - 凸显效率问题

### 20230811 跟康博讨论    
- 对交互图进行图的预训练，操作方法是使用一个encoder将图结构抽出来成为prompt，（可以学到代表性的结构），将当前节点输给encoder，让encoder为结构编码
- 去看一下斯坦福、KDD那篇，然后看一下23arxiv的“伪标签”

### 20230824 跟华为讨论
- 多场景+序列，还没人做，SARNet
- 赶紧看呀，KDD'23 Best Paper，https://arxiv.org/pdf/2305.19523.pdf  Explanations as Features: LLM-Based Features for Text-Attributed Graphs  @Keffee 

### 20230825 陈老师oppo本子
- 一个点：大语言模型个性化推荐能力研究，另一个点：跨域方法
- 研究内容：就写这么短
技术发展趋势（最多）：所有加在一起一页纸，自己写三分之二页，翻译康博的survey；
技术路线（多用论文）：扩充研究内容，加一两个公式，写三分之二页到一页，把康博的翻译翻译，摘几个公式过来，然后把自己那个想法的部分（那个节点信息如何输入大模型）笼统地描述一下写进去就完事了
写的时候围绕个性化角度，之前的个性化建模能力不强，所以要graph交互；把康博论文里的内容仿照这个格式就行；技术路线别写太详细

### 20230825 青创基金
- 华为+腾讯+oppo，打包成多元跨域复杂用户个性化建模
- 写用户大模型个性化（LLM Personalization）
    - 文本
    - 结构
- 周日晚上之前写一个初稿版本
- 无字数要求，看看模板
- 研究内容+技术路线和研究方案

### 20230825 与老师&铭佳师兄讨论
- recsys tutorial，梳理一下材料，准备ppt，40min，pre，

### 20230829 继续关于recsys，与威哥讨论
- 简介（10分钟）（10）
– 推荐系统基础知识
– 用户行为建模的问题表述
– 分类法：常规 UBM、长序列 UBM、多类型 UBM 和带有侧面信息的 UBM

常规UBM（5分钟）（5）
网络结构：RNN，CNN，注意力

长序列UBM（15分钟）
– 内存增强方法
– 用户行为检索方法

多类型UBM（15分钟）（多种类型的行为）（5）
– 行为类型定义
– 多行为融合和预测

带有侧面信息的UBM（15分钟）（多场景）（多模态）（我的）（78个工作）（10）
– 侧面信息来源
– 侧面信息利用

具有深度强化学习的UBM（10分钟）

在线部署的行业实践和性能（10分钟）

总结与未来展望（10分钟） 

OUTLINE

This tutorial focuses on user behavior modeling in recommender systems and will be a 90-minute tutorial. The outline of the tutorial is given as follows

Introduction (10min)
– Recommender system basics
– Problem formulation of user behavior modeling
– Taxonomy: Conventional UBM, Long-Sequence UBM, Multi-Type UBM, and UBM with Side Information

Conventional UBM (5min)
– Network structures: RNN, CNN, Attention

Long-Sequence UBM (15min)
– Memory-augmented methods
– User behavior retrieval methods

Multi-Type UBM (15min)
– Behavior type definition
– Multi-behavior fusion and prediction

UBM with Side Information (15min)
– Source of the side information
– Side information utilization

UBM with Deep Reinforcement Learning (10min)

Industrial practices and performances of online deployment (10min)

Summary and future prospects (10min)

- 注册一下recsys，让它发邀请函，用邀请函申请商务签，
- 有推荐的会议酒店，但是建议自己定...近一点，
- 简介（10分钟）（10）
常规UBM（5分钟）（5）
多类型UBM（15分钟）（多种类型的行为）（5）
带有侧面信息的UBM（15分钟）（多场景）（多模态）（我的）（78个工作）（10）
- A Survey on User Behavior Modeling in Recommender Systems
    - Background
        - 三个研究趋势：长度增长、多样性增加、异质性增加
    - 传统用户推荐
        - 从相对短期的行为序列中提取项目依赖和相关性
        - RNN-based，GRU4Rec(2016)，NARM(2017)，捕捉长短期依赖关系
        - CNN-based，RNN很难捕捉到“下一步的影响是受好几个步骤之前的行为，而非临近行为影响”的行为，Caser(2018)将行为视为时间与潜在维度上的“图像”，NextItNet(2019)引入残差块结构的生成CNN模型
        - Attention-based，在建模任意行为对之间的交互具有优势不会因为编码距离而降低性能。SASRec(2018)自回归预测，DIN(2018)自适应学习与某个项目相关的历史行为中用户兴趣的表示，DIEN(2019)考虑用户兴趣的演化特征，DSIN(2019)学习会话等等
        - Discussion，也有很多不能简单分类到上面的，如MLP(2014), gnn(2021), SURGE(2021)就通过度量学习从行为序列构建了物-物兴趣图
    - Long-Sequence UBM
    - Multi-Type UBM
        - 多类型明确考虑不同的行为类型
        - 行为欸行难以定义，可粗分为宏观行为、围观行为、不同场景行为
        - 多行为多类型，多类型融合
        - 联合预测多种类型的行为（独立预测、级联预测）
    - UBM with Side Information
        - 辅助信息可以分为时间信息、物品属性和多模态信息
            - TiSASRec发现物品对之间的时间间隔传达了关键的知识，TISSA提出时间间隔的GRU
            - FDSA(2019)提出了结合物品ID与类别、品牌和描述文本等属性进行顺序推荐，trans2D(2022)对物品ID和属性进行特征转换
            - p-RNN(2016)分别提取图像和文本特征，SEMI(2021)直接使用预训练的计算机视觉和自然语言处理SOTA来获得表示
        - 如何有效使用辅助信息的表示？
            - p-RNN(2016)直接连接/加权求和，SC-CNN(2022)将辅助信息作为视图，用半因果卷积神经网络捕捉关系，CARCA(2022)使用两分支的多头自注意力框架
            - NOVA-BERT(2021)将辅助信息作为自注意力模块的辅助部分，以学习更好的注意力分布；DIF-SR(2022)使用单独的注意力计算将各种辅助信息解耦，S3Rec(2020)使用两个与属性相关的自监督目标，MISS(2022)提出一个基于CNN的提取器
        - 在将来，异构的边缘信息来源会起决定性的作用

### 20230904 初版RecsysPPT反馈
- 克凡，我觉得总体做的挺好的，PPT的大纲在明细点，每个类型的工作是不是列举几个详细的对应工作会好点，目前PPT内容较少，难以撑起一个section的tutorial
- 对的，代表性工作可以详细展开一下
- 然后，PPT中包含一下学校校徽等元素，并且介绍一下做pre的人

### 20230907 讨论国自然PPT
- 研究背景抄 科技创新2030 本，三个挑战借鉴数字教师本，然后关键科学问题总结参考科技创新2030的关键科学问题总结
- 知识获取、知识组织管理、示范应用，寡妇词解决一下
- 多源异构性：三个点重新总结一下，让栋少总结一下吧

### 20230915 跟威哥讨论ppt
- 帮威哥的outline标一下红
- 统一引用风格
- GCN, RNN部分都改一下，表示一下这种方法是用来做序列推荐的
- item attribute加一页结果
- 多模态第一面加一面
- tutorial，加一些王皓老师工作
- 搜推改成多模态模型
- 重点用颜色标记一下，黑体&标红
- OK. 下飞机以后一直往前走，下电梯，可能刷护照就可以，刷护照之前要填一个singapore arrival card，有卡直接刷护照就能进
- OK, grab/打车，换些现金
- OK, 新加坡法律法规

### 20230925 short review
- 阿里有一篇图的大模型
- agent survey看看
- 分享一下的recsys的见闻

### 20230927 华为讨论
- 别忘了总结一下recsys的学习见闻
- 目前华为的大模型的思路：构建大模型+用户行为的个性化memory，LLM在memory上进行检索，细粒度行为索引精确查询query。
- 皓哥的一个想法：意图检索，然而是不是缺乏数据集支撑？
- 以后的周三组会可以排一个pre+同步进度的形式，pre讲40分钟，四到五个工作，不用订topic？

### 20231007 讨论
- 交互数量越来越多，序列变长（不强调长序列）
- 效率问题
- 去噪问题

- 方法
    - 先过一个fmlp，然后分别进行硬去噪和软去噪并对比
- related work（老的可以没有，新一点好）（找一个中的新的，抄一点，并补上他自己）
    - denoising部分
        - 补一下sigir23的那篇抄fmlp的
        - 补一下非常复杂的那篇
        - 补一下baseline的那几篇
    - 多行为部分
        - 感情倾向换成效率问题

### 20231009 shortreview
- 看一下老师发的代码，尝试把图结构融入llama中
- 抓紧时间报销
- 画图

### 20231009 论文讨论
- 题目emmmmm
- 相关工作太长了，删一点，可能就半页多一点就行了，页数要靠intro撑起来
- preliminaries，就叫问题定义，别写这个了，写problem...
- methodology：写一下overview，看看铭佳师兄的写法
- method结尾说一下，具体的效率和复杂度分析在实验中会有更详细的阐释
- motivation：强调“是多行为的拼合带来了序列长度的增长”，由此带来了效率问题
- soft和hard是两个不同的level，是不是要highlight一下，所以可以强调hard是离散的，soft是连续的
- intro需要一个大帽子，可以说multi-behavior sequential的问题，需要一、二等问题，同时要结合figure1紧密一点阐述问题，现在总-分结构中总的部分太少了
- 故事：拼起来联合建模导致序列长度过长，同时面临噪声问题；on the one hand有点lowb，可以换一下
- 这种写法可能需要一个帽子把三个challenge扣在一起，需要一个“总”；同时三个challenge之间需要转折词来衔接它们
- related work太长了，改短
- method：要强调“为了实现什么”，把目的性讲出来，用一些"to", "for"之类的关键词
- 4.1改叫behavior aware XXX
- 可能用词都需要改一改
- 4.2三个点还没有串起来，需要motivation参与，需要一个帽子扣起来
- 4.2到4.3没有联系句，少了逻辑关系。after we..., we ..., but we ...
- 4.3提别人的related work太多了，可以把第一段拉到intro的challenge？由繁删俭
- 4.3.1 需要reference支持为什么假设数据分布
- 4.3.1 说明一下hp和hn具体意义
- 4.3.2 先做了离散，又做了feature，这样让大家知道这两个之间的关联
- 4.4的motivation有点短了，同时公式(8)需要解释，不能空手放这
- algorithm要加入行号，然后后面就说x行到y行干了什么什么
- 5.1一个问题：为什么要选择这个baseline？

### 20231023 short review
- 能不能把已有推荐模型与大模型的结合变成一种标准形式，graph tool former，找一些能够有代表性的标准流程
- 调研传统推荐+大模型的结合
- re
    - 珽嘉：通过candidate与大模型结合提升效果
    - 一个想法：利用康博工作+GNN explainer构成游走网络
    - 另一个想法：ClickPrompt，将PLM和CTRModel互补，互相为对方生成soft prompt和embedding vector，目前可以看到BIGRec也用了LLM的embedding，但是它使用最后一个token的embedding，而且事实的结果很差（不知道大模型中间变量到底哪个embedding能正确代表目标embedding）

### 20231025 组会
- 一个general问题：参数不要太研究，不要花时间纠结参数，看看铭佳师兄在语雀的包
- 珽嘉有挺多子图选取方法调研，了解一下
- 铭佳师兄发到群里的[那篇](https://arxiv.org/pdf/2308.08459.pdf)，看看它是怎么做的
- 别忘了老师发的[workshop](https://mp.weixin.qq.com/s/pUrqdglF26ww1nDK9hANTA)里面的具体做法
- 考虑到embedding的难度，可能会变成蒸馏，直接用二者的结果进行比较
- 你[KAR](https://arxiv.org/pdf/2306.10933.pdf)还没看呐
- 师兄推荐的数据集论文[NineRec](https://arxiv.org/pdf/2309.07705.pdf)

### 20231101 华为开会
- KAR使用的通用域大语言模型，发现在垂域不理想，不知道经过SFT后效果如何
- COLLM，冯福利；WSDM中了另一篇开源+闭源；
- ONCE: Boosting Content-based Recommendation with Both Open- and Closed-source Large Language Models
- CoLLM: Integrating Collaborative Embeddings into Large Language Models for Recommendation
- LLMRec: Large Language Models with Graph Augmentation for Recommendation 
- VQ-Rec Learning Vector-Quantized Item Representation for Transerable Sequential Recommenders
- （这段只是随意考虑）item太长了，相关长序列；多行为情况下关系怎么刻画
- 后续关注跨域情况下怎么进行图学习，围绕着用户行为怎么刻画
- 用户历史memory做一个分层画像，缓解长序列问题

### 20231102 偷听港城大宣讲
- 研究生院培养办王丽老师（较为和蔼1）
- 得到导师同意-联系城大导师-提交申请
- 问一下基于什么对学生进行选拔——只要把本科至今为止的成绩提交
- 问一下资格考试是什么东西
- 托福只要成绩单能出来就行了，晚一点送到也是ok的；**六级没有时间要求**
- 指标是单独预留的，与原有指标是不同的
- 名额：20人，报上来的人只要符合条件都会推荐给城大，但是一共最多20人，所有专业一起定的；
- 两条路都走不现实，那边走了这边难走
- 平均GPA3.0，只有城大部分的课，毕业的话基本上easy，申请的话主要看本科成绩
- 最终决议：给研二同学准备的

### 20231104 MLA
- meta learning在学什么：
    - 学一个meta-initialization
    - finetune一个task-specific优化
    - 在推荐上，可以把每个用户当成一个task
    - 如何解决conflict gradient？使用improvement function

### 20231109 大模型组会
- CVPR2022 RQ-VAE，解决query的生成表征崩塌问题

### 20231207 大模型组会
- ERNIE如何对齐token和entity呢？
- BERTNET来构建用户-物品关联性
- box-embedding如何定义

### 20231211 晨会
- 看看，试试（皓哥言）

### 20231214 威哥快速讨论
- 华为方面的下一步思路：
    - 大方向：继续沿着大模型表征生成方向进行实验。
    - 研究重点：
        1. 结合用户属性的多行为表征。可能可以包含多域、多行为等问题。
            - 多行为/多域数据的预处理和大模型理解。
            - 多行为-结构化数据结合和大模型输入。
        2. 用户交互记录与大模型的结合。
            - 利用小型编码器为交互记录生成embedding，替换大模型的第一层embedding(类似CoLLM)。
            - 利用大模型替代过去的语言编码器，进行改进。
            - 多类型数据输入大模型。
- 赶紧处理三件事：
    - 将输入DIN的序列信息去掉，看看效果下降了多少
    - 将序列信息输入SASRec，看看提升了多少
    - 将数据魔改一下，把所有用户评价过的电影都加上，别管评分了，跟他爆了