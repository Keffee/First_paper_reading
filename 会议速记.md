<!-- 接下来的内容是各个开会、讨论的记录 -->
#### 20230317 美团进度
- 缺少公开数据集
- \*没想到过去的实习生，也不完全跟着实验走，也要自己做research
- 想法：右边是搜索，左边两个行为数据是行为数据（推荐），
- 最近去调研一下最近的搜推融合方法（包括冠琪师兄发在群里的内容）
- 论文列表：
    1. Knowledge Enhanced Personalized Search（知识图谱）
    1. Keyword-Based Knowledge Graph Exploration Based on Quadratic Group Steiner Trees（在复杂知识图谱上的搜索）
    1. FedPS: A Privacy Protection Enhanced Personalized Search Framework（个性化搜索中的隐私泄露问题）
    1. Attentive Long Short-Term Preference Modeling for 5. Personalized Product Search（用长短期记忆网络辅助个性化搜索）
    1. Embedding-based Retrieval in Facebook Search（facebook上的个性化搜索）
    1. Modeling User Behavior with Graph Convolution for Personalized Product Search（对用户连续行为图进行建模，挖掘用户偏好（可这和搜推有什么关系呢？）
    1. CL4CTR: A Contrastive Learning Framework for CTR Prediction（进行特征表示工程）
    1. Efficient and effective training of language and graph neural network models（GNN结合大规模语言模型做推荐，先看看吧）
    1. ReprBERT: Distilling BERT to an Efficient Representation-Based Relevance Model for E-Commerce（接下来的四篇都看过了，都旨在解决搜索结果与用户意图不匹配的问题）
    1. Graph-based Weakly Supervised Framework for Semantic Relevance Learning in E-commerce
    1. Learning a Product Relevance Model from Click-Through Data in E-Commerce
    1. Weakly Supervised Co-Training of Query Rewriting and Semantic Matching for e-Commerce

#### 20230324 组会
- 回去看看instructive few-shot的那篇
- 回去看看tiger
- 两篇复现一下
- 研究一下冠琪师兄的蒸馏方法，看看和transformer+gnn有什么关系
- autodl——线上服务器

#### 20230407 组会
- 目前师兄都在跑代码，尝试复现各自的论文（并且调试）
- 一种思路的转变->转向生成式网络

#### 20230411 讨论
- 思考搜推融合能不能继续下去
- 思考prompt方法能不能融进来，比如永强师兄的框架能不能直接把prompt部分改成输入搜索query的方式

#### 20230418 会议记录
-（回去看一下HGCL与其他人的对比，看看别人的NDCG是不是真有那么高）（此条删除）
- 尹铭佳
    - 工作规划
        - 使用预训练的多行为长序列建模
            - 图增强的序列推荐
            - 长序列问题优化效率问题
            - 多行为长序列问题
    - 已有工作
        - [SRGNN](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1811.00855), [GCSAN](https://www.ijcai.org/Proceedings/2019/0547.pdf), [GCEGNN](https://dl.acm.org/doi/pdf/10.1145/3397271.3401142)
    - 已有实验结果：
        - 数据集：ML-M, Amazon-beauty, Diginetica, Gowalla
        - 模型：GRU4Rec, SASRec(BCE), SRGNN, GCSAN, GCEGNN
        - SASRec+图对比学习：对于稀疏数据集有着较好提升，但是对稠密矩阵的效果与单纯使用SASRec无明显提升
            - **提问**：取了几个负样本？**回答**：只用了一个
        - SASRec+DirectAU: 在稀疏数据集上产生了较大提升，MF+Di的效果远小于SASRec+DirectAU，可能是因为需要引入更复杂的模型才能支持
            - **提问**：是否应该增加采样，因为现在此领域已经有很多相关结论，应当尝试更多负样本的情况
- 徐翔
    - 超长序列召回：
        - [阿里SIM](https://arxiv.org/pdf/2006.05639.pdf)，soft search效果更好，但是效率较差，因此使用hard search，效果并没有差很多，但是效率好了，可以正常上线
        - [华为UBR](https://arxiv.org/pdf/2005.14171.pdf)
        - [阿里ETA(End-to-End User Behavior Retrieval)](https://arxiv.org/abs/2108.04468)，这是一个CTR模型，更新频率更高，训练/推理成本更低，端到端，
        - [美团SDIM(Sampling-based-Deep Interest Modeling)](https://arxiv.org/pdf/2205.10249.pdf)，使用哈希指纹，在提高AUC的同时也达到了非常高的效率
        - [ADFM(Adversarial Filtering Modeling on Long-term User Behavior Sequences for Click-Through Rate Prediction)](https://arxiv.org/abs/2204.11587)，
            - **提问**：对这样的长序列，是如何处理里面的每个item的？
            **回答**：聚类处理用户的behavior，去除冗余item；
            - **提问**：BSU框架中为何先进行分桶后还要再对user behavior重新top-k分组？这样的处理有意义吗？
            **回答**：留待之后详细研究
        - [快手TWIN: TWo-stage Interest Network for Lifelong User Behavior Modeling in CTR Prediction at Kuaishou](https://arxiv.org/pdf/2302.02352.pdf)，解决目标不一致问题
        - Efficient Dense Retrieval
- 郭威
    - 长序列、多行为进展：
        - 端到端：
            - 长序列：[UBR](https://arxiv.org/pdf/2005.14171.pdf)、[SIM]((https://arxiv.org/pdf/2006.05639.pdf))、[ETA](https://arxiv.org/abs/2108.04468)、[SDIM](https://arxiv.org/pdf/2205.10249.pdf)、ETA+ 
            - 多行为：MBSTR，HPMR
        - **提问**：目前端到端效果如何？
        **回答**：沿着逐步开发的路线，UBR->SIM->ETA，发现端到端的ETA效果会更好一些，更能捕捉全部item的特征。
        - 预训练：word2vec，Transformer，GNN；需要一些新颖的东西来进行提升
        - 下游如何微调

#### 20230425 旁听北京航天局参观实验室
- 北京航天自动控制研究所简介
    - 控制航天运载工具的运行之类的
    - 宇航智能控制技术全国重点实验室
        - 高速飞行的制导控制方法：飞得稳，投得准
        - 精确制导：最末端的制导
        - 光学制导：合作下，非合作下、对抗下
        - 控制系统一体化：设备轻小型、国产化、全自主
        - 快速发射

#### 20230505 组会
- 看看每年的best paper，提升提升？

#### 20230510 组会
- query到click有一个噪声变量，铭佳师兄有一篇就是这个方法，
- 17号把所有结果都跑通
- lightgcn，bpr
- 一个问题：目前的负采样由于负采样时采到正样本的概率很低，故而没有考虑去除负采样中的正样本的操作（因为太慢了），但是最后表述的时候应该要注意一下

#### 20230524 组会
- 看看ICLR吧，比较不水（WWW, KDD, CVPR）
- 日后投稿组内要先过一遍
- 以后读一下因果x多行为（如果可能的话看一看CoT）
- 现在集中在可信上：可解释、鲁棒、安全

### 20230614 组会
- 所有人40分钟快速过一下个人工作
- 我跟永强师兄一组，一共20分钟，轮流进行：一个人详细讲一个人少讲
- 然后talk的那个人再讲40分钟

### 20230616 讨论本子
- 未来还是数据的问题，缺数据就没办法
- 模型架构都基本一样，最关键的还是数据的配比+清洗等
- 格式完全仿照2号word写，思路可以看看pdf

### 20230619 short review
- 看一看ID替代的gpt embedding

### 20230621 组会
- 去看一看cvpr、acl的预训练的、去噪的、多行为的文章，现在阅读量太少了

### 20230626 short review
- 以后也要调研prompt learning相关的论文（prompt+因果+去噪+多行为）

### 20230628 自监督学习分享
- BYOL，用平均值作teacher，单view作student，从而进行自监督

### 20230703 short review
- 可以看一些OOD论文来跟去噪、多行为结合
- 看一看libo的主页
- 这周就先梳理去噪/OOD的文章

### 20230711 深夜讨论多行为是什么
- 目标：用户行为建模的survey
- 问题：用户行为建模和序列推荐的区别在哪里
- 如何切分**多行为**建模
（理一下每个问题的假设）（弄清楚问题和假设之后才考虑方法）
    - 预训练、微调（甚至把这个单独做一个问题点）
    - 多类型的异质融合
    - 多类型的泛化
    - 单任务vs多任务
        - 单任务：负迁移（去偏、去噪）、行为关系建模、鲁棒性
        - 多任务：任务平衡优化、任务设计、效率问题
    - （跨域vs单域）

——先去看华为survey里面提到的文章，然后再去看近期的论文，进老师的系统看看最新的文章
- 跨场景算不算多行为？
- 一到两个礼拜讨论出结果

### 20230712 华为项目讨论
- 威哥：
    - 多行为结合稀疏用户序列长度扩充；多行为预训练和微调
    - LLM：长序列+多行为
- liuyong：
    - 过去的长序列建模建立在传统推荐场景，现在能不能把对话式交互看作长序列
    - 现有的长对话序列问题比较粗糙，可以做...吗？
    - 在对话历史中进行信息检索；所以在长序列问题不仅仅局限在推荐场景，但是实际上可以继续考虑对话场景
    - 检索不一定那么准确，所以大模型需要很强（检索部分提升效率，大模型部分进行修正）
- 威哥：
    - 大语言模型放到预训练来做（大模型通用知识和小模型垂域知识联合学习）
- 现在的合作项目框架：
    - 长序列：多个场景已经打通基本项目，SDIM尝试，目前长度100，在向200-1000尝试
    - 多行为：内部不同业务域数据相互打通（音乐、视频、浏览器），拿到几十个跨域的不同行为，embedding后给到下游任务（在target domain，主要是广告）（目前的ID还是全部不同）
    - 一个想法：将文本信息利用大模型融合到item embedding中，从而便于跨域
- 接下来想做的方向：
    - 长序列：召回方式、召回粒度、召回多样性、自适应召回长度

### 20230719 华为项目讨论
- 预训练的一个问题，预训练数据和finetune数据分布可能会很不一样
- 我们想解决的问题：**跨域推荐**！通过目前已有的多个域数据来增强目标域的效果
- 数据形式：纯ID序列
- 现有的路线：
    - 预训练形式：计算通用embedding（以及如何处理embedding）（以及如何更改embedding生成模型）
    - KG transfer和LLM transfer
    - 更倾向于使用CTR上的方法
    - 迁移形式：尝试利用多域信息进行向目标的迁移

### 20230724 short review
- 这周总结出来跨域序列推荐的论文
- 生成式序列...是什么？和跨域有什么关系？
- 老师最近打算自己做个工作，需要同学帮忙跑实验（

### 20230726 华为项目讨论
- 跟康博约个时间讨论大语言模型接进跨域推荐（利用文本辅助信息迁移）
- 继续调研CIKM今年的投稿文章中跨域序列推荐文章

### 20230727 和师兄关于大模型偏好迁移的讨论
- 皓哥：借助大模型探索物品ID之间的关联性
- 康博：文本关联性easy，但是对item之间关联性有点困难
- 康博：大模型学习ID之间结构的目的是什么呢，用大模型会更好吗？
- 皓哥：希望大模型能学到结构知识
- 康博：直接用大模型做推荐，可以，但是大模型学不到结构化知识，从这个角度上讲...采一些子结构，当成token来做embedding，可能可以？预训练模型究竟怎么和图进行结合呢？之前有工作是直接把所有文本信息放进去
- 现在可以做：深层次的语义理解；结构的transfer，可以用structure token，或者用路径的方式输入大模型之中。根本上来说就是语言与结构进行语义对齐
- 核心目标：怎么学item的予以关系来建模item关联；怎么把item之间的结构关系和文本语义信息通过大模型来建立相似度关联性
- 观其师兄之前做了一个任务，看看能不能把这个思想用在大模型之中
- 也可以看一些最近的图上的LLM，以及多模态大模型（如何把视觉信息输入语言模型）（理解成语义模态和结构模态）（先了解一下思路）
- [链接1](https://mp.weixin.qq.com/s/dQPbNg01aAbRIJt2WdBEgw) [链接2](https://zhuanlan.zhihu.com/p/622220960)
- 可用数据集：Amazon，MDB，arXiv（手动处理量大）
- 有问题问问康博，这周先把这方面文章看一下，代码方面找康博，prompt方面问问永强师兄
- 如何得到对齐的structure embedding
- 对于路径挖掘的代码已经有了，主要关心的是如何得到structure embedding
- 路径不能错，先通过复现部分跨域方法（基于知识图谱的等），打通pipeline，再将大模型替换进去

### 20230728 帮忙写陈老师军工本子
- 第一点：如何处理多源异构数据？多源异构数据融合技术
    - 数据清洗与预处理
    - 多源数据深度表征技术
    - 多源知识实体抽取技术
    - 多源知识实体对齐技术
    - 多源知识体系构建技术
    - 跨模态知识迁移技术
- 第二点：有哪些大数据分析技术方法？J需能源大数据分析技术（维博师兄）
    - 图像处理技术
    - 语音处理技术
    - 文本处理技术
    - 视频处理技术
    - 多模态处理技术
    - **多模态知识图谱技术（和下面分成两块，但是都作为一个大点）**
    **多模态推理技术（多模态融合除去知识图谱）**
- 我们写一个**开题报告**，不像申请书，更像技术报告：主要写研究目的（一页左右？）(motivation)、相关情况分析(related work)、研究内容与技术路线、研究进度与成果形式
- 字数要求：每个点1w字左右，每个同学2k字就行
- ddl是8.10，一周写完就好
- 要写之前先列一下点，给老师看看，确认以后再写
- 对于分配到自己的课题，要写的是国内外研究现状+主要研究内容和技术路线related work差不多700-800字，然后1500字左右的研究内容和技术路线，研究内容和技术路线分开，模仿7J
- 写general一点，网上找资料也行（但是别重），别太domain了，还是要前沿一点的
- 周末先构思一下，这个大点里面最好再分3个左右小点
- 周末出大纲，周一开始写，周五前能有初稿

### 20230802 华为组会
- 现在考虑将item文本信息和序列结构信息输入大模型，具体而言，将用户作为起始，接下来在序列里采样，输入采到的文本和结构信息
- 看一看赵鑫的文章，先复现出来

### 20230807 short review
- 补几个prompt的基准实验
- 

### 20230807 跟师兄讨论
- 我们是多行为多任务，把四个行为的预测角度战胜多任务
- 单目标需要多任务重新训，多任务需要
- 不提sasrec
- 我们想提取共现知识的提取和高效的迁移，但是现在想要解决多任务还没有用预训练+微调范式的，我们认为这是因为它们难以根据下游任务进行微调（未解耦，但我们使用了prompt，达成了完全解耦），于是我们取代了MMOE，更加简单高效
- 我们解决的是多任务问题，目前只能建很多个单任务或者一个多任务模型，但是前者效率低，多任务难以加入新任务；加上多任务有效果跷跷板问题。之前没能做是因为ID没有语义，但是我们解决了

### 20230808 讨论AAAI
- related work，prompt learning in recommendation（看看arxiv上有没有新的，把审稿意见那几篇也拿进来），预训练+微调的baseline快速调研
- 调研矢量图画法

### 20230810 讨论
- 想做的是多行为预训练＋微调的事
- 如何在预训练和微调阶段如何考虑多行为序列推荐的问题，讲传统序列推荐方法解决不了我们问题的困难点在哪
- 预训练一个contribution，微调一个contribution
- related work
    - 序列推荐-多行为-预训练放在多行为里面，有一部分工作关注多行为里的预训练问题
    - prompt learning
- baseline
    - 为了公平，其他人可以把多行为拼一拼
    - 凸显效率问题

### 20230811 跟康博讨论    
- 对交互图进行图的预训练，操作方法是使用一个encoder将图结构抽出来成为prompt，（可以学到代表性的结构），将当前节点输给encoder，让encoder为结构编码
- 去看一下斯坦福、KDD那篇，然后看一下23arxiv的“伪标签”

### 20230824 跟华为讨论
- 多场景+序列，还没人做，SARNet
- 赶紧看呀，KDD'23 Best Paper，https://arxiv.org/pdf/2305.19523.pdf  Explanations as Features: LLM-Based Features for Text-Attributed Graphs  @Keffee 

### 20230825 陈老师oppo本子
- 一个点：大语言模型个性化推荐能力研究，另一个点：跨域方法
- 研究内容：就写这么短
技术发展趋势（最多）：所有加在一起一页纸，自己写三分之二页，翻译康博的survey；
技术路线（多用论文）：扩充研究内容，加一两个公式，写三分之二页到一页，把康博的翻译翻译，摘几个公式过来，然后把自己那个想法的部分（那个节点信息如何输入大模型）笼统地描述一下写进去就完事了
写的时候围绕个性化角度，之前的个性化建模能力不强，所以要graph交互；把康博论文里的内容仿照这个格式就行；技术路线别写太详细

### 20230825 青创基金
- 华为+腾讯+oppo，打包成多元跨域复杂用户个性化建模
- 写用户大模型个性化（LLM Personalization）
    - 文本
    - 结构
- 周日晚上之前写一个初稿版本
- 无字数要求，看看模板
- 研究内容+技术路线和研究方案

### 20230825 与老师&铭佳师兄讨论
- recsys tutorial，梳理一下材料，准备ppt，40min，pre，

### 20230829 继续关于recsys，与威哥讨论
- 简介（10分钟）（10）
– 推荐系统基础知识
– 用户行为建模的问题表述
– 分类法：常规 UBM、长序列 UBM、多类型 UBM 和带有侧面信息的 UBM

常规UBM（5分钟）（5）
网络结构：RNN，CNN，注意力

长序列UBM（15分钟）
– 内存增强方法
– 用户行为检索方法

多类型UBM（15分钟）（多种类型的行为）（5）
– 行为类型定义
– 多行为融合和预测

带有侧面信息的UBM（15分钟）（多场景）（多模态）（我的）（78个工作）（10）
– 侧面信息来源
– 侧面信息利用

具有深度强化学习的UBM（10分钟）

在线部署的行业实践和性能（10分钟）

总结与未来展望（10分钟） 

OUTLINE

This tutorial focuses on user behavior modeling in recommender systems and will be a 90-minute tutorial. The outline of the tutorial is given as follows

Introduction (10min)
– Recommender system basics
– Problem formulation of user behavior modeling
– Taxonomy: Conventional UBM, Long-Sequence UBM, Multi-Type UBM, and UBM with Side Information

Conventional UBM (5min)
– Network structures: RNN, CNN, Attention

Long-Sequence UBM (15min)
– Memory-augmented methods
– User behavior retrieval methods

Multi-Type UBM (15min)
– Behavior type definition
– Multi-behavior fusion and prediction

UBM with Side Information (15min)
– Source of the side information
– Side information utilization

UBM with Deep Reinforcement Learning (10min)

Industrial practices and performances of online deployment (10min)

Summary and future prospects (10min)

- 注册一下recsys，让它发邀请函，用邀请函申请商务签，
- 有推荐的会议酒店，但是建议自己定...近一点，
- 简介（10分钟）（10）
常规UBM（5分钟）（5）
多类型UBM（15分钟）（多种类型的行为）（5）
带有侧面信息的UBM（15分钟）（多场景）（多模态）（我的）（78个工作）（10）
- A Survey on User Behavior Modeling in Recommender Systems
    - Background
        - 三个研究趋势：长度增长、多样性增加、异质性增加
    - 传统用户推荐
        - 从相对短期的行为序列中提取项目依赖和相关性
        - RNN-based，GRU4Rec(2016)，NARM(2017)，捕捉长短期依赖关系
        - CNN-based，RNN很难捕捉到“下一步的影响是受好几个步骤之前的行为，而非临近行为影响”的行为，Caser(2018)将行为视为时间与潜在维度上的“图像”，NextItNet(2019)引入残差块结构的生成CNN模型
        - Attention-based，在建模任意行为对之间的交互具有优势不会因为编码距离而降低性能。SASRec(2018)自回归预测，DIN(2018)自适应学习与某个项目相关的历史行为中用户兴趣的表示，DIEN(2019)考虑用户兴趣的演化特征，DSIN(2019)学习会话等等
        - Discussion，也有很多不能简单分类到上面的，如MLP(2014), gnn(2021), SURGE(2021)就通过度量学习从行为序列构建了物-物兴趣图
    - Long-Sequence UBM
    - Multi-Type UBM
        - 多类型明确考虑不同的行为类型
        - 行为欸行难以定义，可粗分为宏观行为、围观行为、不同场景行为
        - 多行为多类型，多类型融合
        - 联合预测多种类型的行为（独立预测、级联预测）
    - UBM with Side Information
        - 辅助信息可以分为时间信息、物品属性和多模态信息
            - TiSASRec发现物品对之间的时间间隔传达了关键的知识，TISSA提出时间间隔的GRU
            - FDSA(2019)提出了结合物品ID与类别、品牌和描述文本等属性进行顺序推荐，trans2D(2022)对物品ID和属性进行特征转换
            - p-RNN(2016)分别提取图像和文本特征，SEMI(2021)直接使用预训练的计算机视觉和自然语言处理SOTA来获得表示
        - 如何有效使用辅助信息的表示？
            - p-RNN(2016)直接连接/加权求和，SC-CNN(2022)将辅助信息作为视图，用半因果卷积神经网络捕捉关系，CARCA(2022)使用两分支的多头自注意力框架
            - NOVA-BERT(2021)将辅助信息作为自注意力模块的辅助部分，以学习更好的注意力分布；DIF-SR(2022)使用单独的注意力计算将各种辅助信息解耦，S3Rec(2020)使用两个与属性相关的自监督目标，MISS(2022)提出一个基于CNN的提取器
        - 在将来，异构的边缘信息来源会起决定性的作用

### 20230904 初版RecsysPPT反馈
- 克凡，我觉得总体做的挺好的，PPT的大纲在明细点，每个类型的工作是不是列举几个详细的对应工作会好点，目前PPT内容较少，难以撑起一个section的tutorial
- 对的，代表性工作可以详细展开一下
- 然后，PPT中包含一下学校校徽等元素，并且介绍一下做pre的人

### 20230907 讨论国自然PPT
- 研究背景抄 科技创新2030 本，三个挑战借鉴数字教师本，然后关键科学问题总结参考科技创新2030的关键科学问题总结
- 知识获取、知识组织管理、示范应用，寡妇词解决一下
- 多源异构性：三个点重新总结一下，让栋少总结一下吧

### 20230915 跟威哥讨论ppt
- 帮威哥的outline标一下红
- 统一引用风格
- GCN, RNN部分都改一下，表示一下这种方法是用来做序列推荐的
- item attribute加一页结果
- 多模态第一面加一面
- tutorial，加一些王皓老师工作
- 搜推改成多模态模型
- 重点用颜色标记一下，黑体&标红
- OK. 下飞机以后一直往前走，下电梯，可能刷护照就可以，刷护照之前要填一个singapore arrival card，有卡直接刷护照就能进
- OK, grab/打车，换些现金
- OK, 新加坡法律法规

### 20230925 short review
- 阿里有一篇图的大模型
- agent survey看看
- 分享一下的recsys的见闻

### 20230927 华为讨论
- 别忘了总结一下recsys的学习见闻
- 目前华为的大模型的思路：构建大模型+用户行为的个性化memory，LLM在memory上进行检索，细粒度行为索引精确查询query。
- 皓哥的一个想法：意图检索，然而是不是缺乏数据集支撑？
- 以后的周三组会可以排一个pre+同步进度的形式，pre讲40分钟，四到五个工作，不用订topic？

### 20231007 讨论
- 交互数量越来越多，序列变长（不强调长序列）
- 效率问题
- 去噪问题

- 方法
    - 先过一个fmlp，然后分别进行硬去噪和软去噪并对比
- related work（老的可以没有，新一点好）（找一个中的新的，抄一点，并补上他自己）
    - denoising部分
        - 补一下sigir23的那篇抄fmlp的
        - 补一下非常复杂的那篇
        - 补一下baseline的那几篇
    - 多行为部分
        - 感情倾向换成效率问题

### 20231009 shortreview
- 看一下老师发的代码，尝试把图结构融入llama中
- 抓紧时间报销
- 画图

### 20231009 论文讨论
- 题目emmmmm
- 相关工作太长了，删一点，可能就半页多一点就行了，页数要靠intro撑起来
- preliminaries，就叫问题定义，别写这个了，写problem...
- methodology：写一下overview，看看铭佳师兄的写法
- method结尾说一下，具体的效率和复杂度分析在实验中会有更详细的阐释
- motivation：强调“是多行为的拼合带来了序列长度的增长”，由此带来了效率问题
- soft和hard是两个不同的level，是不是要highlight一下，所以可以强调hard是离散的，soft是连续的
- intro需要一个大帽子，可以说multi-behavior sequential的问题，需要一、二等问题，同时要结合figure1紧密一点阐述问题，现在总-分结构中总的部分太少了
- 故事：拼起来联合建模导致序列长度过长，同时面临噪声问题；on the one hand有点lowb，可以换一下
- 这种写法可能需要一个帽子把三个challenge扣在一起，需要一个“总”；同时三个challenge之间需要转折词来衔接它们
- related work太长了，改短
- method：要强调“为了实现什么”，把目的性讲出来，用一些"to", "for"之类的关键词
- 4.1改叫behavior aware XXX
- 可能用词都需要改一改
- 4.2三个点还没有串起来，需要motivation参与，需要一个帽子扣起来
- 4.2到4.3没有联系句，少了逻辑关系。after we..., we ..., but we ...
- 4.3提别人的related work太多了，可以把第一段拉到intro的challenge？由繁删俭
- 4.3.1 需要reference支持为什么假设数据分布
- 4.3.1 说明一下hp和hn具体意义
- 4.3.2 先做了离散，又做了feature，这样让大家知道这两个之间的关联
- 4.4的motivation有点短了，同时公式(8)需要解释，不能空手放这
- algorithm要加入行号，然后后面就说x行到y行干了什么什么
- 5.1一个问题：为什么要选择这个baseline？

### 20231023 short review
- 能不能把已有推荐模型与大模型的结合变成一种标准形式，graph tool former，找一些能够有代表性的标准流程
- 调研传统推荐+大模型的结合
- re
    - 珽嘉：通过candidate与大模型结合提升效果
    - 一个想法：利用康博工作+GNN explainer构成游走网络
    - 另一个想法：ClickPrompt，将PLM和CTRModel互补，互相为对方生成soft prompt和embedding vector，目前可以看到BIGRec也用了LLM的embedding，但是它使用最后一个token的embedding，而且事实的结果很差（不知道大模型中间变量到底哪个embedding能正确代表目标embedding）

### 20231025 组会
- 一个general问题：参数不要太研究，不要花时间纠结参数，看看铭佳师兄在语雀的包
- 珽嘉有挺多子图选取方法调研，了解一下
- 铭佳师兄发到群里的[那篇](https://arxiv.org/pdf/2308.08459.pdf)，看看它是怎么做的
- 别忘了老师发的[workshop](https://mp.weixin.qq.com/s/pUrqdglF26ww1nDK9hANTA)里面的具体做法
- 考虑到embedding的难度，可能会变成蒸馏，直接用二者的结果进行比较
- 你[KAR](https://arxiv.org/pdf/2306.10933.pdf)还没看呐
- 师兄推荐的数据集论文[NineRec](https://arxiv.org/pdf/2309.07705.pdf)

### 20231101 华为开会
- KAR使用的通用域大语言模型，发现在垂域不理想，不知道经过SFT后效果如何
- COLLM，冯福利；WSDM中了另一篇开源+闭源；
- ONCE: Boosting Content-based Recommendation with Both Open- and Closed-source Large Language Models
- CoLLM: Integrating Collaborative Embeddings into Large Language Models for Recommendation
- LLMRec: Large Language Models with Graph Augmentation for Recommendation 
- VQ-Rec Learning Vector-Quantized Item Representation for Transerable Sequential Recommenders
- （这段只是随意考虑）item太长了，相关长序列；多行为情况下关系怎么刻画
- 后续关注跨域情况下怎么进行图学习，围绕着用户行为怎么刻画
- 用户历史memory做一个分层画像，缓解长序列问题

### 20231102 偷听港城大宣讲
- 研究生院培养办王丽老师（较为和蔼1）
- 得到导师同意-联系城大导师-提交申请
- 问一下基于什么对学生进行选拔——只要把本科至今为止的成绩提交
- 问一下资格考试是什么东西
- 托福只要成绩单能出来就行了，晚一点送到也是ok的；**六级没有时间要求**
- 指标是单独预留的，与原有指标是不同的
- 名额：20人，报上来的人只要符合条件都会推荐给城大，但是一共最多20人，所有专业一起定的；
- 两条路都走不现实，那边走了这边难走
- 平均GPA3.0，只有城大部分的课，毕业的话基本上easy，申请的话主要看本科成绩
- 最终决议：给研二同学准备的

### 20231104 MLA
- meta learning在学什么：
    - 学一个meta-initialization
    - finetune一个task-specific优化
    - 在推荐上，可以把每个用户当成一个task
    - 如何解决conflict gradient？使用improvement function

### 20231109 大模型组会
- CVPR2022 RQ-VAE，解决query的生成表征崩塌问题

### 20231207 大模型组会
- ERNIE如何对齐token和entity呢？
- BERTNET来构建用户-物品关联性
- box-embedding如何定义

### 20231211 晨会
- 看看，试试（皓哥言）

### 20231214 威哥快速讨论
- 华为方面的下一步思路：
    - 大方向：继续沿着大模型表征生成方向进行实验。
    - 研究重点：
        1. 结合用户属性的多行为表征。可能可以包含多域、多行为等问题。
            - 多行为/多域数据的预处理和大模型理解。
            - 多行为-结构化数据结合和大模型输入。
        2. 用户交互记录与大模型的结合。
            - 利用小型编码器为交互记录生成embedding，替换大模型的第一层embedding(类似CoLLM)。
            - 利用大模型替代过去的语言编码器，进行改进。
            - 多类型数据输入大模型。
- 赶紧处理三件事：
    - 将输入DIN的序列信息去掉，看看效果下降了多少
    - 将序列信息输入SASRec，看看提升了多少
    - 将数据魔改一下，把所有用户评价过的电影都加上，别管评分了，跟他爆了
将大模型侧用户交互序列给去掉，看看效果降了多少
多行为长序列交互
结合属性的用户行为（movie-lens 不同的评分甚至可以是不同的行为）
如何多类型
注重用大语言模型替换旧有工作
多行为、长序列、序列交互attention,can

### 20231218 晨会
- 多行为有没有数据集
    - [Tmall数据集](https://tianchi.aliyun.com/dataset/140281)
    - Yelp数据集用得很多，而且大家就是按照喜好程度打行为标签的，类似地，Movie-Lens也会使用喜好程度做行为标签
        - 例如：IJCAI '22, [Self-supervised graph neural networks for multi-behavior recommendation](http://shichuan.org/doc/134.pdf)（S-MBRec）
- Once方法怎么办
- 明天之前把大模型推荐的相关文章整理一下，尤其KAR, CTRL, ClickPrompt, CoLLM, LLMRec

### 20231219 华为讨论
- 调研对齐方法
- 继续沿着ML-1M的路线尝试
- 把对齐方法送进去试一试

- 问问威哥他们有什么结果

### 20231226 华为讨论
- 急
    - 处理数据集
- 还行
    - 看一下star team群里的两篇文章
    - 推荐模型embedding输入大语言模型，然后SFT
    - 取出LLM的最后一层embedding替代现有的文本->LLM->文本->BERT->embedding
- 不急
    - Yuanfajie：
    - 如何在保持ID能力不变的情况下，将文本信息融入

### 2024010125
- 急：
  - 生成伪ID，https://mp.weixin.qq.com/s/ql9Ig_8LETCIyGSVifMbpw，参考多域ID对齐，用大模型生成ID，解决跨域问题
  - 基于生成式模型的对齐工作，比如VAE
  - 处理数据集
- 还行
  - 看一下star team群里的两篇文章
  - 推荐模型embedding输入大语言模型，然后SFT
  - 取出LLM的最后一层embedding替代现有的文本->LLM->文本->BERT->embedding
- 不急
  - Yuanfajie：
  - 如何在保持ID能力不变的情况下，将文本信息融入

### 20240104
- 使用别人处理好的数据集，因为自己处理可能造成结果下降（
- Alignment的survey
- 搞清楚目前的(ID)生成方法的问题定义是什么，先弄明白该干嘛，再跑实验

### 20240208
- 别忘了看威哥的两篇文章（四篇文章）

### 20240229 线上讨论
- memory
  - Graph neural network in linkedln temporal graph
  - 先验信息；聚类，条件引导；conditionalguide(加在最后一层);
- RAG
  - 大模型更倾向于检索出来的内容；adaptive message passing
- 推荐agent
  - 传统的用户建模-基于LLM的用户意图理解-检索增强-可控生成决策；One for all(设计结构，)
  - Agentforrecommendation;(开始推动起来)
  - 这个东西目前效果不太好，就不太好做（皓哥可能觉得难度比较大）
- 皓哥对未来工作的总结
  - 技术上：必须要进行大模型结合（去看下mega模型）
  - 停下序列推荐，换成agent memory的建模（更换故事）
  - 要做落地
- 威哥：
  - 三个方向可以落地
    - 长序列多粒度的落地
    - 多行为
      - 多个子序列（DMT）
      - 融合成一个大序列
      - one for all也可以用在这里
    - 跨域
      - one for all架构能否
- 分工
  - 翔哥：继续无证实习，看能不能作出有影响力的文章
  - 铭博：data centric
  - 强哥：去噪的深入工作
  - 我的：看看Google的意图文章，做个讨论
- 看一下CVPR24，梳理一下

### 20240304 面上讨论
- 我的部分的相关工作短了，但是不要分太多段，就写两三段就行，加入FFT，然后扩增大模型部分，多写一点；总结里面写局限性的时候呼应上我们确定的标题
- 通常话术：针对xxxx挑战，研究xx问题，探索xx研究内容，达到了xx效果
- 研究内容：跨域协同增强的表征对齐方法研究
- 创新点：用了xx技术，解决了xx挑战问题，达到了xx效果
- 第二部分参考区域联合基金的写法，仔细看2.2.1那里写的内容“小点研究内容的写作思路”
- 画图参考项目申请书图7图8
- 方案参考鸾康师姐的部分，intro参考前面的要求

### 20240306 面上二次讨论
- 应用（往用户建模上贴合，侧重讲实验效果，按青基模板来）
  - sigir22 级联 信息检索
  - sigir23 transfer冷启动
  - cikm hyperbolic 链接预测检索
  - 徐翔应用-华为中效果提升

### 20240307 面上三次讨论
- 年度研究计划要更新
- 相关工作、科学问题、创新型、研究方案、年度计划（研究基础）、框架图对应调整

### 20240312 华为讨论
- 推荐大模型有没有可能去做
- 个性化大模型去噪
- 大语言模型提特征别做了，做一点更有意思的方向

### 20240315 华为会议
- 铭佳师兄
  - 铭佳师兄的两个方案都交给徐翔来做可能比较好
  - 方案一
    - 频域去噪
    - 复杂度在FMLP和Self-Attention之间
    - 跟多行为关联存在问题，需要之后威哥和周睿对一下多行为的对应做法
  - 方案二
    - spect-Former
    - 多个频域模块和attention模块进行堆叠
  - **让永强师兄把两个实验结果贴一下**
  - 铭佳师兄自己方案
    - 跨域的通用表征
    - 域内表征增强+各推荐域之间的知识迁移+训练时的trick
      - 单域目前用特征增强和表征均匀对齐性进行对比学习，对齐是针对user和item进行对齐，均匀是_______
      - 知识迁移：表征中的一部分给一个域用，另一部分给另一个域用，学出每个域的item表征和mask
        - 如何引入好的方法学习mask
        - 可能可以用对比学习学习mask，但是需要进一步探索
        - 皓哥：可以试试one for all的框架，用一个encoder编码所有数据，然后用不同的decoder进行解码
          - 周天铭佳师兄、永强师兄和威哥约个时间讨论一下one for all
          - 通用预训练（DSSM）（聚焦在怎么训）（而one for all聚焦在怎么用）
- 徐翔
  - 改进检索模块
    - 尝试ETA
    - SDIM
      - 行为Emb转化为二进制哈希签名
      - 从整个序列中收集与候选项签名相同的行为项
      - 线性聚合行为Emb得到用户兴趣
      - 疑问：线上业务是否和SDIM的场景相同
    - 利用hash表存储embedding，便于高速查找
    - 要跟公司对一下，看一下用户数量过大怎么解决
  - 改进特征侧
    - TWIN
      - 将视频特征集分为视频固有特征和user-videocross特征
      - 注意力计算中K的线性投影是关键的计算瓶颈
      - 检索过程使用简化的多头目标注意力机制
      - 固有特征Emb映射预计算、参数共享
      - 交叉特征映射将维度压缩为一维bias
      - **可以提一下两阶段一致性**
    - DGIN
      - 跟业务对一下
  - 检索特征利用
    - 根据时延问题推一下
    - mamba-rec可以在tf上实现，尝试后发现效果不错
    - 可以先试一试傅里叶变换方法
  - 下周和应用市场的同事对接一下

### 20240315 华为会议纪要
- 铭佳
  - 铭佳师兄的两个方案都交给徐翔来做可能比较好
  - 方案一
    - 频域去噪
    - 复杂度在FMLP和Self-Attention之间
    - 跟多行为关联存在问题，需要之后威哥和周睿对一下多行为的对应做法
  - 方案二
    - spect-Former
    - 多个频域模块和attention模块进行堆叠
  - **让永强师兄把两个实验结果贴一下**
  - 铭佳师兄自己方案
    - 跨域的通用表征
    - 域内表征增强+各推荐域之间的知识迁移+训练时的trick
      - 单域目前用特征增强和表征均匀对齐性进行对比学习，对齐是针对user和item进行对齐，均匀是_______
      - 知识迁移：表征中的一部分给一个域用，另一部分给另一个域用，学出每个域的item表征和mask
        - 如何引入好的方法学习mask
        - 可能可以用对比学习学习mask，但是需要进一步探索
        - 皓哥：可以试试one for all的框架，用一个encoder编码所有数据，然后用不同的decoder进行解码
          - 周天铭佳师兄、永强师兄和威哥约个时间讨论一下one for all
          - 通用预训练（DSSM）（聚焦在怎么训）（而one for all聚焦在怎么用）
- 徐翔
  - 改进检索模块
    - 尝试ETA
    - SDIM
      - 行为Emb转化为二进制哈希签名
      - 从整个序列中收集与候选项签名相同的行为项
      - 线性聚合行为Emb得到用户兴趣
      - 疑问：线上业务是否和SDIM的场景相同
    - 利用hash表存储embedding，便于高速查找
    - 要跟公司对一下，看一下用户数量过大怎么解决
  - 改进特征侧
    - TWIN
      - 将视频特征集分为视频固有特征和user-videocross特征
      - 注意力计算中K的线性投影是关键的计算瓶颈
      - 检索过程使用简化的多头目标注意力机制
      - 固有特征Emb映射预计算、参数共享
      - 交叉特征映射将维度压缩为一维bias
      - **可以提一下两阶段一致性**
    - DGIN
      - 跟业务对一下
  - 检索特征利用
    - 根据时延问题推一下
    - mamba-rec可以在tf上实现，尝试后发现效果不错
    - 可以先试一试傅里叶变换方法
  - 下周和应用市场的同事对接一下

### 20240317 华为落地会议
- 还不快去看interest journey
- 能否SFT，如何SFT，如何构建推荐数据的SFT
- Meta工作很重要

### 20240319 华为讨论
- 调研interest journey相关工作，思考以下方向：
  - 根据interest text算相似度，基于相似度从其他用户处扩增信息
  - 文本的表征：如何表征得更好：RAG+外部数据库（腾讯引入WikiPedia）；KDD挑战赛（看一下工业界用法）
  - 兴趣：MIND, COMNREC, MULTICLR, Octopus, SINE, Re4, GIMIRec，如何将兴趣建模得更好（推荐系统多兴趣建模）
  - 垂域：如何激发能力（SFT/prompt）
  - 现在的主要任务是提取好的interest journey，CTR只是一个好评价的任务

### 20240320LLM-用户兴趣提取讨论
- 问题：
  - 聚类算法：使用多兴趣模型进行学习，比如多头注意力；协同信号训练一个MF和文本信号做对齐（CLIP）；这两个拼在一起缺乏创新（提炼出来聚类算法的问题，看看有什么创新）
  - 聚类的时候：长序列如何聚类
- 进展：
  - 逸全：
    - 论文复现：
      - 基于interest journey
      - 数据集：ML-1M
      - 对类别数据+title聚类后使用大模型之后发现：得到的都是电影种类，需要提升tag质量
      - prompt: You are a helpful recommendation assistant that is able to extract a user'sinterestusing a listof movieshe or shehaswatched.Given a JSoN list ofmovie titles consumed by the user, return a JSoN list of 3,descriptivekeywords or phrases thatbest describes a user's taste in moviesfrom thelist provided.
    - 初步计划：
      - 0. evaluation; a) CTR model evaluation| b) conversational recommendation c) tag-generation evaluation (tricky)
      - 1. every interest is a embedding, every cluster we mean-pool embeddings, and possibly add cluster statistics 
      - 2. Improve generated tag quality : generated tag too similar to actual genre (need to add other information, actor, synposis) 
      - 3. Improve user sequence clustering quality: using tile to cluster might not be too appropriate, (other information to other clustering, actor, director, synopsis, comment, CF embedding?)
      - 引入协同信号、如何SFT、找到评估方法
- 下周计划：
  - 逸全：
    - 如何评估
  - 克凡：
    - 聚类算法实现+SFT方案（微调开源模型）
- 个人记得点
    - Sim能不能按最近距离找？
    - item的词表示方式是使用显著词词表进行词01表征的

### 20240326 华为讨论
- 数据泄露，重跑
- 看能不能加一下辅助信息

### 20240327 huawei 讨论
- 克凡
  - 本周进度：
    - 基于TF-IDF和TF-IDF+词向量进行聚类
    - 聚类结果作为去噪方法提升数据质量
    - 跑之后效果很差
  - 下周计划：
    - 使用BERT进行对比试验
    - 将tag信息融入表征中观察效果
- 逸全：
  - 本周进度：
    - 先把训练集截断，聚类生成decription，生成tag，只在大的cluster传播tag
    - 基于title为每个cluster生成prompt
  - 下周计划
    - 考虑下一步使用部分user先行试验
- 数据记录：（这个数据出了问题，没顺利按照时间顺序排序）
base	        HR@10: 0.412	NDCG@10: 0.23
cluster	      HR@10: 0.313	NDCG@10: 0.17
cluster_2vec	HR@10: 0.283	NDCG@10: 0.157
cluster_bert	HR@10: 0.389	NDCG@10: 0.214
- concept embedding

### 20240401 华为讨论
- 大量调研concept generation+LLM的论文，看看相关工作怎么做的
- 直接把item打标，看看效果
- 使用分类器打标是否可行
- 具体内容去看20240401讨论进度.pptx

### 20240403 huawei讨论
- 克凡
  - 利用聚类进行去噪
    - 效果显著下降
    - TF-IDF相比直接用BERT向量进行聚类会丢失更多信息
  - 利用聚类添加信息
    - 效果略微提升
    - 聚类后的tag相比直接使用title能够带来更高质量信息（效果提升）
  - 大模型生成结果比对
    - 由于存在同义词，无法使用基于文本匹配的方式进行评估
  - 下周计划
    - concept embedding调研，寻找有没有可以复现的想法
- 逸全：
  - DeepFM利用bert embedding加入为user特征
    - loss异常的大，加入了bert——emb之后效果下降了
    - bert的维度太高了，需要降维
  - 下周计划：
    - 解决模型训练时的loss过高问题
    - 解决embedding利用问题
    - 增加baseline

### 20240408 huawei分享
- 把LLM切成两半，前一半fix获得表征，后一半可训地接受前面转化好的token（不知所谓）
- FolkScope
  - LLM获取用户行为意图
  - 知识图谱和购买情况关系不大
  - 用LLM构建意图KG
  - 利用co-buy进行
- 看一看life-long learning
  
### 20240412 huawei分享
- 逸全：
  - cluster_description_embedding(绑定用户)(来自BERT)利用MLP进行降维
    - 降维后效果略微提升
    - 加入随机初始化噪声后，效果相差不多
  - 下一步计划：
    - 确定基线序列长度；截断user序列
    - 对比不聚类直接在sequence LM embedding vs sequence 接 cluster embedding 对比效果
    - 信息泄露(?)
    - 看是否能通过聚类方式引入更长序列
- 克凡
  - 本周进度：
    - concept初步尝试
      - 引入genre作为concept再对齐有效果，但是方法陈旧重复
      - 利用聚类进行item扩增：效果变差
  - 问题：
    - review噪声很多
    - 长序列，如何引入更多信息
    - 多行为，多域如何融合
  - 下一步计划：
    - Prompt 设计
    - SFT：genres当监督信号
    - 能否指导模型抽item相关的信息：预定义一些如价格、属性等的concept，用LLM从review中抽
    - 和COSMO对比
    - 引入更多文本如何去噪：关键问题：哪些文本是user相关的（引入web或者tmdb(用title关联信息)或者分类器或者SFT或者规则）（跟珽嘉讨论下能不能用rag来去噪）
    - 总结：
      - 如何找到user相关的文本？
      - 如何引入web和tmdb等外部数据集信息？
      - rag？SFT？prompt tuning？
- 威哥论文分享：
  - RecSys'23(Short)
    - 多行为，由用户兴趣预测用户类别来进行预测

### 20240416 华为meeting
- VQ方向
  - 了解一下RQ-VAE，Conditional valuation of auto-encoder
  - 如何引入协同信号+语义信号？
  - 跟文嘉讨论下
- RAG方向
  - 检索内部信息的方法：D2K: Turning Historical Data into Retrievable Knowledge for Recommender Systems
  - RAG应当检索外部信息
- UIA图方向
  - 可以试试
- life-long learning
  - 暂且不考虑

### 20240417 华为meeting
- 汪克凡
  - 实验结果
    - SFT后效果提升
  - 下一步计划
    - 使用VQ/RQ-VAE based 方法进行聚类
    - 全局和局部聚类 
    - 协同信号引入
    - 三阶段方法：vq训练，推荐任务，重新vq编semantic code
- 逸全
  - 结论
    - 30 most recent user_behavior对比全数据效果提升0.02
    - 引入user cluster description as user emb没有效果提升
  - 下一步计划
    - 新的交互就判断是否属于旧聚类，相隔固定时间/出现新聚类再更新

### 20240417 旭林皓哥讨论
- 旭林
  - recommendation中一套表征难以完整表示item/user
  - 2106.12622

### 20240423 华为讨论
- 读读文章
  - Modeling User Viewing Flow Using Large Language Models for Article Recommendation
    - 利用大模型捕捉用户之前文章中的信息，进行文章的CTR预测
    - 大模型为文章生成摘要
    - BERT编码标题+摘要，然后和属性嵌入拼接
  - TBIN: Modeling Long Textual Behavior Data for CTR Prediction
    - 解决文本长序列问题
    - 首先使用BERT进行预编码，然后LSH（局部敏感哈希）分桶
    - 使用Bucket-based Self-Attention（B-SA）进行桶内自注意力
    - 分块
    - 使用Chunk-based sSelf-Ateention（C-SA）进行块内注意力
    - 使用Shifted Chunk-based Self-Attention（SC-SA）进行循环移位块间注意力
  - Breaking the Length Barrier: LLM-Enhanced CTR Prediction in Long Textual User Behaviors
  - 何老师sigir24文章：LLaRA: Large Language-Recommendation Assistant

### 20240430 内部讨论
- vq，rq，aq，从数学角度切进去看区别
- 和tiger的区别
- NIPS '23, [Recommender Systems with Generative Retrieval](https://arxiv.org/pdf/2305.05065.pdf)(TIGER)
  - 简略版：
    - 给定一个item的文本描述，使用预训练的文本编码器生成dense的embedding，然后量化生成语义ID，再根据语义ID反推出语义ID对应的embedding，经过平均池化就能得到每个语义ID的embedding了
    - 之后使用这种语义ID（也就是说embedding皆已固定）进行推荐，接下来构造负例，分别是把ID半修改生成的负例、把同batch的其他预测ID作为负例；通过置换矩阵使得多个域能对齐
  - 重看版：
    - 避免矩阵分解范式，直接预测候选id的端到端生成范式，尾部是一个生成式检索模型
      - (WWW23)VQ-Rec建立可转移的推荐系统而非检索
        - VQ-Rec认为item rep.和text rep.过于紧密，问题如下：
          - 过分强调文本相似性，忽略序列性
          - 文本的不同表述可能导致在语义空间的映射不同
        - 目的：预训练一个可转移的序列推荐器
        - 转移中，训练一个转移矩阵，这个转移矩阵基于Birkhoff-von Neumann定理进行优化，用来转移码元嵌入
      - 生成检索来自于文档检索
    - 使用文本编码器为item生成embedding，然后使用量化获得语义ID，优点有3：
      - 基于语义的ID在相似item上天然具有相似性
      - 避免内在反馈循环(inherent feedback loop)，推荐系统会倾向于忽略长尾节点
      - 减轻存储压力
    - 在生成语义ID之后，直接将语义ID送入seq2seq模型进行训练，例如，i_1=(3,2,4), i_2=(7,4,1), i_3=(2,1,5)，则输入(3,2,4,7,4,1,2,1,5)，来预测接下来三个id
- 什么是vq-vae？
  - vae相比ae而言，保障了encoder之后得出的结果是满足高斯分布的；方法就是使用ELBO损失，但是问题是：vq-vae用的其实是ae而非vae
  - 
- vq，rq，aq
  - vq是向量量化方法，其实主要作用是压缩，并且忽略掉太细节的东西
  - rq是递归vq，vq是单层rq，rq是对每一步的残差在量化，消耗时间提升精度
  - 自适应量化，动态根据数据量和数据特性决定量化的策略

### 20240508 讨论
- 逸全：
  - 之前的问题
    - 之前的聚类方法不太好
    - 超过LLM context
    - 增量推理速度慢
  - 当前方案
    - 行为切片50
    - 转文本编码，50个行为内聚类
    - 生成summary
  - 优势
    - 支持增量更新
    - 用户-aware的模式
  - 目前的问题：
    - 不同聚类的生成描述存在重叠
    - 老summary可能不更新
  - 后续计划：
    - 看能否随着用户增量更新summary池
- 克凡：
  - 已有工作
    - 完成VQ算法搭建
    - 基于数据获得聚类结果
  - 下一步计划
    - 将SASRec和chenxu的工作作为基线进行对比，希望提升效果
    - 将聚类结果作为user feature放入sasrec中观察效果
    - 最终目标：获得更好的user tagging，用于提升序列推荐效果
- 聚类是行为信息转文本，然后bge编码
- 评估方式：CTR预估
- 改进工作：
  - 基于开域
    - 基于CTR数据集验证效果，公开数据集（movielens，amazon-book）
  - 基于闭域
    - 基于用户历史行为，给用户生成意图
    - 人工标注意图
    - 评估意图准度
- 量化结果拼上去试试
- 码的嵌入中心decoder出文字，快速
- 后续好好做序列推荐

- 基线：sasrec
- 引入文本信息：优于sasrec
- baseline1：chenxu的工作：切片
- 怎么更好利用文本信息：提取用户意图，基于意图增强
- 聚类，根据类来提取用户意图；目标是用于做序列推荐的，做出更好的user tagging
- 读文章：Knowledge adaptation from large language model to recommendation for practical industrial application

### 20240514 华为讨论
- tokenizer，能不能把模态信息引进来
- P5相关
- 梳理基线：人大+快手+冯福利
  - Learning Vector-Quantized Item Representation for Transferable Sequential Recommenders
  - A Multi-facet Paradigm to Bridge Large Language Model and  Recommendatio
  - Knowledge Adaptation from Large Language Model to  Recommendation for Practical Industrial Applicatio

  - CALRec: Contrastive Alignment of Generative LLMs For Sequential Recommendation
  - Improve Temporal Awareness of LLMs for Sequential Recommendation

### 20240515 华为讨论
- kefan
  - 上周工作：
    - 完成聚类+SASRec的模型测评
      - 引入文本信息效果超过SASRec baseline
      - 聚类并没有带来明显提升
      - SFT后效果下降
  - 下周计划
    - 考虑到大模型特点，更换大模型为冻结的llama3-8b
    - 直接从大模型侧输出embedding，省去文本编码器
  
- yiquan
  - 上周工作：
    - 之前自己搞的代码和 chengxu 报的 AUC,logloss 差了几十个点·和 chengxu 要了一些代码，然后打通数据处理，模型训练，评估流程·目前基线已经差不多打平：
    - 我们DIENbaseline0.8095，他们DIENbaseline0.7988·目前在调试在CTR模型加入LLM描述embedding，当前还没有显著提升。
  - 下周计划：
    - 复现chengxu的效果，提升auc
    - 加入时间聚类

### 20240523 华为讨论
- transrec确认下
- 输入是只有序列/序列加特征
- tokenizer是一个单独工作
- 推荐信息给LLM和LLM信息给推荐， 这两种方式分开
- calrec是否进行了全亮微调
- 观察模型输出，也要基于输出进行分类
- 别忘了写overleaf
- 能否用mask区分不同item之间的token
- TransRec细讲一下
- 

- WWW24 快手 搜推融合

- 数据集：Amazon，MIND
- 基线：重跑华为这边的基线
- 搜推能不能更紧密，只对query进行提升不够新颖
- 搜推问题
  - 搜&推偏移非常严重，当前是用对比学习，推荐的时候只从搜索处提出相关的兴趣，现在引入语言模型，能不能用语言模型对query更深地理解来match。
  - 有的query里的click很少，使用diffusion进行补充，现在可能可以用语言模型基于query和item的意图进行困难例挖掘；以及query和seq交给大模型获取意图
- 搜推问题
  - query的文本序列比较异质
  - research比较复杂点，上线恐怕比较简单，两边embedding取一下就ok了
- 实验计划：
  - 模仿VQ-Rec写对比损失
  - Recformer，修改mask结构（先不了）
  - 修改recformer的pretrain_model部分，写成self-attention+bias（先不了）
  - longformer+Lora（先不了）
  - 在VQ-Rec的代码里面（VQ-Rec直接基于UniSRec编写而且更加复杂，因此我们也基于UniSRec进行编写）
    - 加入位置编码（token，position，item_position）
    - 网络结构：多个网络，第一个head正常，第二个head（mask，同一个item内部不交互），第三个head（捕获同个item内部交互）
    - loss层：多个head之间的对齐

序列推荐的工作：
纯文本的路线：unisrec, recformer，Transrec(生成式模型)
tokenizer的路线(生成式)：tiger(RQ-VEC), VQ-REC, LETTER(RQ-VEC + token和协同信号的对齐)

input: unisrec(adapter)， recformer（position encoding），tiger(RQ-VEC), VQ-REC（VQ）, LETTER(RQ-VEC + token和协同信号的对齐)
模型：通用的模型,  bert, longformer(lora)
Loss: unisrec(对比)， recformer（自编码 + 对比）


4 个 token
(1) 位置编码: token, position, item_position
(2) 网络结构: 多个head，第一个head，第二个head（同一个item内部不交互），第三个head（捕获同一个item内部的交互）
(3) loss: 多个head之间的对齐；

现在：
A100-40G正在用5号模型finetune
D13 正在用原本的模型finetune（效果基本能保证）（finetune完成，效果基本得到保证）
8卡4090正在pretrain

### 20240529 华为讨论
item比code会有损失
code效果实际上比不过不用code的方法，那么我们为什么要用呢，就是如下解释
The Elephant in the Room: Rethinking the Usage of Pre-trained Language Model in Sequential Recommendation https://arxiv.org/pdf/2404.08796 
- 研究PLM在SR中的适配性，发现，可能PLM并不适合SR任务，提出了一种基于PLM的初始化方法
- 现有问题
  - 只基于文本的工作，通常情况下在交互足够的情况下比不过正常序列模型
  - 当引入序列信息时，大多数未考虑适配问题
  - recformer
    - 首先预训练一个基于文本的推荐模型（MLM+IIC）
    - 然后预生成item enmbedding，利用这个微调整个模型M+item embedding I，这个过程中会诞生一个最好的M-I组合
    - 现在已经更新了M和I了，然后现在完全固定I，只更新M
  - 发现不同层的attention的关注点不同，分为0-3/4-7/8-11，4-7关注每个item的第一个token，8-11类似SASRec，关注近期的token和关键token，也就是说，其实recformer更加接近SASRec，而非LongFormer。也就是说，RecFormer非常冗余。进一步实验发现，只调一部分的LongFormer，效果更好Table1
  - 问题：
    - 需要PLM这么强的能力吗？简单模型能替代吗？
    - 如何在SR中利用PLM？
    - PLM集合到SR中应该是什么样的？
  - 结论：
    - PLM能力没有被充分激发
    - 基于行为微调之后的PLM编码效果很好，但是普通的PLM编码没什么用。
    - 基于行为微调之后的PLM编码在下游任务上继续训练效果很好。
    - 当SR的架构和训练目标和PLM相似的时候效果更好（从BERT4Rec>SASRec中得出，个人存疑）

Bowen Zheng, Yupeng Hou, Hongyu Lu, Yu Chen, Wayne Xin Zhao, and Ji
Rong Wen. 2023. Adapting Large Language Models by Integrating Collaborative Semantics for Recommendation. arXiv preprint arXiv:2311.09049 (2023)
- 直接利用LLM进行推荐，大模型捕获语言语义，难以利用
- 

 https://arxiv.org/pdf/2405.03110 Vector Quantization for Recommender Systems:
 AReview andOutlook
 - 下一步工作
   - 调研论文，梳理出LLM用于tokenizer的related work工作，以及这些工作存在的缺陷（重点）
   - 梳理LLM用于行为建模的工作，为survey做基础
   - （3）text 输入 llm 得到embedding，基于embedding来pretrain-tune；下游任务做fine-tune（finetune的时候还调transformer）；（该做法改为下面的）
   - （1）不要code，语言模型生成的embedding做训练的效果；（2）要code，但是code池化，这个paper的做法；（3）我们的做法。这三个做法均不pretrain
   - （现在发现batch_size=40是最接近边缘的了，我们就都用40）

- 逸全
  - 新方案
    - 把过往的描述喂给大模型，生成新聚类描述
    - 新描述存储在用户兴趣描述pool
    - 描述生成embedding
  - 聚类做法
    - 固定聚类数量
    - 使用语义聚类
    - 设定阈值，当新item和cluster区别很大的时候
  - LLM申城文本/聚类在CTR的用法
    - Mean - Pooling
    - Attention - Pooling (每个用户用相同 query 去搞 attention -- Chengxu 当前方案)
    - Target Attention Pooling (Target-item 作为 query, soft-max pooling)
    - Search - based pooling (类似 SIM)
      - a. Recent 5 user behaviour item 找 top-k cluster 内的 item 检索给 CTR
      - b. Target - item 找 top-k cluster 内的 item 检索给 CTR
    - 记录用户记忆，分层记忆来提取用户兴趣

### 20240605 华为讨论
- yiquan
  - 增加一个步骤，先让大模型检索对应描述，然后判断已有的描述是否和当前电影聚类相关，然后再用之前相关的描述生成新行为的描述
  - 即便当前描述和用月户聚类不相关，大模型倾向于说聚类和某个已有的描述相关。
    - 还在对这个prompt做一些调整
    - 这个可能是个问题，涉及到用户意图的多样性
- kefan
  - 不用绝对位置编码，使用相对位置编码
  - item粒度encoder

### 20240610 和威哥单独讨论
- 后续使用ppt进行整理
  - TIGER
  - LETTER
  - Recformer
  - transrec
  - mbstr
    - 解决多行为中的依赖问题：如何在细粒度的项目级别上建立异构的多行为依赖关系？不同的行为对下一步行动的影响程度不同，这些不同的行为序列如何建模？多行为序列如何表示？
    - 这里，使用交互的attention进行解决
  - Bridging Language and Items for Retrieval and Recommendation.(BLAIR)
    - 现代方法缺乏语义，端到端语言模型跨域能力不强，PLM编码缺乏针对推荐场景的设计
    - 处理了一个Amazon Reviews23数据集，相比过去的Amazon数据集，Categories更多，user、item、review、token、metadata均更多
    - 考虑一对输入：上下文c（user review）和项目特征m（item features），则cm分别能生成一个嵌入，我们将这两个嵌入进行对比学习，同个对为正，同一batch中不同对为负
    - 同时添加原有backbone损失
    - 在多种下游任务（推荐作为编码器/搜索）上可以看到取得了良好效果。
  - Personalized Behavior-Aware Transformer for Multi-Behavior Sequential Recommendation
  - Adapting Large Language Models by Integrating Collaborative Semantics for Recommendation.
  - Multi-Behavior Generative Recommendation.(MBGen)
    - 现有问题：现有工作缺乏细粒度的行为-item建模
    - 解决问题：同时预测行为类型和交互项目，通过两阶段方法先预测行为类型再预测item
    - 编码层，修改RQ-VAE，第一层使用PQ编码，第二层基于第一层，为第一层的每个code单独编码，第三层作为歧义消除层
    - encoder使用MoE范式，E分别是user embedding，behavior embedidng和三个code embedding
    - decoder使用多任务，包含目标行为下item预测、给定行为下item预测、行为和item联合预测、预测行为四个task
    

### 20240613 华为讨论
- 威哥
  - 介绍了一种基于query-behavior的query分类方法，用query之间共同使用item的共现信息来构建query-query图，然后对这个图进行无监督聚类，从而得到聚类中心，利用聚类标签作为label的ground truth训练FastText进行分类
- yiquan
  - 利用聚类生成文本，然后存储如user interest pool
  - 如果有过往的聚类描述，就将过往描述和新的item文本喂给大模型生成新的描述
  - 改进方向:
    - 考虑few-shot/ICL
- kefan
  - 分享了现在的工作进度
  - 改进方向：
    - RQ应当存在重要性，我们希望学到code的关联和重要性
    - Item横轴，token纵轴，二维transformer
    
  - Personalized Behavior-Aware Transformer for Multi-Behavior Sequential Recommendation
  - Adapting Large Language Models by Integrating Collaborative Semantics for Recommendation.
  - trans2d
  - 皓哥那边，关键审稿nips
    - End-to-end Learnable Clustering for Intent Learning in Recommendation(ELCRec)
      - 目前的意图识别方法可以大体认为是EM算法，E步通过聚类获得意图，M步自监督方法更新嵌入，但是存在问题：聚类的时候速度慢，并且限制可扩展性；同时聚类和优化算法分离导致性能差
      - 拼接user behavior embedding得到user embedding（这一步很平常）
      - 可微聚类(ELCM)
        - 前半部分，loss为不同簇中心间的距离，同时除以$(k-1)k$确保大小适当，同时使用l2正则化提升网络收敛性（时间复杂度$O(k^2d)$，空间复杂度O(kd)）
        - 后半部分，loss目的是聚类中心与意图对齐，在这里，意图被拉向所有聚类中心而非最近的簇中心，避免聚类误差导致的信息偏差（时间复杂度O(bkd), 空间复杂度O(bk+bd+kd)）
      - 意图辅助对比学习(ICL)
        - 通过mask, crop（裁剪） and reorder（重排）能得到增强后的user embedding，这两个user embedding进行对比学习，在这里，两个user emb都经过了聚类中心的增强（拼接或加和）
        - 把最近的聚类中心embedding当成正例，其余聚类中心当成负例做对比学习
      - 加了个next_item_prediction损失
  - cikm审稿
    - On Uncertainty of Large Language Models for Recommendation
      Overall recommendation: -1
      Reviewer's confidence: 3
      Relevance to CIKM: 3
      Originality of the Work: 2
      Technical Soundness: 3
      Quality of Presentation: 2
      Impact of Ideas or Results: 4
      Reproducibility of Methods: 2
      Detailed Comments to the Authors:
        The paper presents a framework using the Plackett-Luce model to estimate ranking probabilities and quantify prediction uncertainty with entropy, assessing the reliability of LLMs in recommendations. By incorporating latent variables for prompts, it separates primary sources of uncertainty. Experiments confirm that prediction uncertainty effectively indicates LLM-based recommendation reliability.

        Strong points:
          1. The paper presents an innovative viewpoint by focusing on the uncertainty of LLMs. It explores methods to improve output quality through the quantification of LLM uncertainty.
          2. The study conducts experiments across multiple models. These experiments demonstrate the superiority of the proposed method.
        Weak points:
          1. The paper does not clearly address how the proposed uncertainty quantification method can enhance the output quality of the model, and it lacks detailed information on how to leverage the quantified uncertainty for fine-tuning. Additionally, the paper is not open-sourced.
          2. Although the experimental section demonstrates the framework's effectiveness on various LLMs, the baselines used for comparison lack novelty.
          3. The paper does not compare its results with other large models or traditional sequential recommendation models using metrics such as NDCG@k, which raises doubts about the actual benefit of the uncertainty quantification method for recommendation tasks.
        Summary to support your recommnedation:
          The paper introduces an innovative framework that quantifies the uncertainty of large language models (LLMs) to enhance recommendation reliability. While the study demonstrates promising results across multiple models, it falls short in clearly explaining how the quantified uncertainty improves output quality and lacks detailed fine-tuning guidelines. Additionally, the absence of comparisons with other advanced models and traditional metrics weakens the validation of its effectiveness.
  - 使用cri和azu两个新数据集进行

### 20240618讨论
做个表格，搞清楚做哪些实验，为什么做，怎么做
思路：对比yuanfajie，使用embedding迁移多域多场景会导致协同信号不足，
因为有很多稀疏特征之间的协同，现在表征不足，使用
特征存在稀疏性，稀疏特征使用embedding存在欠拟合，使用VQ则弥补了这一部分，但是对热门feature可能又表征不好了，因此要进一步说明
- 完成
  - 把embedding范式改成编码空间为code的范式
  - Pre增加DCNv2
- 待办
  - 阅读Xlightfm, DHE
  - use id相关实验
  - Related work：传统CTR，对比量化方法的

### 20240627华为讨论
- codebook增大256，然后四个code改成4个10再拼在一起从而得到40维的新embedding。

### 20240701 新讨论的新纪录
- 小于512的看看能不能共享embedding table
- 新特征是分配默认值还是vq学习新编码
- 高频的特征应该有独享的embedding，低频的特征共享embedding，后面优化时也可以考虑下这个点

- pq方法除了降低内存还有什么优势，尝试通过为稀疏特征分配聚类，保持高频特征独有性
- 和单阶段xlightfm效果对比一下

### 20240714 跟威哥讨论related work和现有结果
- 我们的优势：
  - 第一个点：分布的角度，正则+加权，code的分布更加好，重要的特征能够建模独特性，同时覆盖到更多的code
  - 第二个点：分布得更加均衡，对比学习
- 和related work对比
  - 与xlightfm
    - 他是单阶段的，只在fm上做了，与业界兼容性很差，而我们是两阶段
    - 它的code没有考虑ctr预估的特点，然而code是一个长尾分布，频次会有多少差异，因此必须要考虑code分布，我们引入正则和对比来解决了这个问题
  - 与rq-vae base模型
    - 他们是召回，我们是CTR，是精排任务（只有xlightfm与我们相同）
    - 量化方式，它们用的是rq-vae，我们的pq比他好（需要实验证实）
  - 与vq-rec
    - 量化部分没做正则，它们是在推荐部分做的，和我们就已经很不同了
- 我们的贡献点：
  - 
- 已完成
  - 实验结果对齐（把PQ原始方法效果压下去），取消FiBiNET
  - 一定是要统计logloss的结果
  - 赶紧弄好发给华为让华为在自己的数据集上验证
  - 消融实验还是重跑一下
- 下一步工作
  - 调研OPQ的具体公式
  - 增加一个rq的实验结果
  - 一定要比一下xlightfm
  - 测内存和时延可以只做embedding部分，甚至可以只主观计算
    - 内存可以计算出结果
      - 完全正常情况下（cut_down=100000, code_dim=1024）
        - Criteo: 13.00%
        - Avazu: 2.34%
      - 使用更强的压缩（cut_down=10000, code_dim=512）
        - Criteo: 1.88%
        - Avazu: 2.02%
      - 在最极限情况下，仅对于压缩对象而言
        - Criteo: 0.558%
        - Avazu: 0.321%
      - Criteo: 2086329
        - 切断：1835508
        - 我们的：5*1024*4=20480+250821=271301
        - 极限一点：19*256*4=19456+1712=21168
        - DHE: 26*256*4=26624
        - xLightFM: 19*256*4+7*128*4=21248
      - Avazu: 1298621
        - 切断：1276471
        - 我们的：2*1024*4=8192+22150=30342
        - 极限一点：7*256*4=7168+1080=8248
        - DHE: 22*256*4=22528
        - xLightFM: 7*256*4+15*128*4=14848
  - 我们的超参分析数据：
    - alpha(横轴) 0.1, 0.01, 0.001, 0.0001
      - criteo: 0.8073, 0.8087, 0.8105, 0.8098
      - avazu: 0.7425, 0.7521, 0.7543, 0.7537
    - beta(横轴) 0.1, 0.01, 0.001, 0.0001
      - criteo: 0.8095, 0.8105, 0.8098, 0.8086
      - avazu: 0.7527, 0.7543, 0.0.7537, 0.7521
    - d(横轴) 256, 512, 1024, 2048
      - criteo: 0.8096, 0.8102, 0.8105, 0.81055
      - avazu: 0.7527, 0.7533, 0.7536, 0.7537
    - m(横轴) 2, 4, 8
      - criteo: 0.8100, 0.8105, 0.8098
      - avazu: 0.7531, 0.7537, 0.7528
  - 热力图数据来源：Criteo C16，后400个

- 要做的事：
  - **极端重要，先写**
    - 这两个新表不好贴呀，回头去群里确认下
    - 表格补上（注意，时延分析先别放）
    - 重构preliminary，不要考虑user了，只输入特征输出01
    - 基于重构的preliminary，重写method部分，也是，尤其是4.1.1，不要再写用户之类的了，“就是从特征的纬度来写的，输入100个特征，变换成embedding，然后过神经网络，可以和introduction我加的两句话呼应上”（不要忘了下面的嘱咐）
  - 自己这边
  - 威哥：
    - 写作的时候一句话一行
    - 提一下embedding远端拉取会消耗额外的时延，我们这个不需要远端拉取了，具体的耗时我问一下平台侧同事（这是时延分析的内容）
    - 实验部分，预训练模型的影响没有写，这个要补
    - method 第二点，加个引用说明分布不均匀是客观存在的
    - intro最后改，
  - 皓哥：
    - method部分，完全重构，这个两边都提到了，是说写法要遵从：提出问题，如何解决，好处优势，这三段论
    - baseline归类写一下，同时补充新baseline
- **做完的事：**
    - 图贴上

- 日程：
  - 8.5 
    - 贴完ef表和indust表还有预训练模型表，以及写上对应的文字
    - 重构preliminary
    - baseline归类
    - 挂上reference（至少挂一点）
  - 8.6 
    - 完成折线热力两张图
    - 考虑动机图画法、要不要画
    - 修改method，对应图片写文字
    - 挂上reference（至少挂一点）
  - 8.7
    - 完成ef表和indust的全部内容
    - 挂上reference
    - 扫尾，好好休息，准备明天冲刺
  - 8.8
    - 听皓哥安排

目前提出了显存占用太大的模型：
HydridHash, QRTrick, BinaryCode

可能用到的信息：
CNN ctr：CCPM
GRU ctr：DIEN
transformer ctr：Autoint, BST, DMT 
MLP: 很多了，w&d，deepfm，dcn
GNN：FiGNN, GCNCTR

临时：
  超参分析，重写
  dataset，重构
  5.7的部分，表补上
  最后的industry，补全
  time memory分析，写匀一大坨
  ablation部分，不要写一大坨

  实验部分：性能、效率、深入分析，ablation重新组织下塞到深入分析里，超参和case study可有可无

  我得在finding123都提炼一下贡献点
  传统模型效率一坨
  已有的量化模型迁移能力差、效果表现查
  5.1.3的99%这里强调一下是embedding table
  table4的标题要强调一下是embedding table



  embedding压缩的区别点，找到推荐中特有的东西

  现在的embeddingtable太大，导致模型程度没什么意义了，所以引入
  传统方法进行了优化，但是仍然存在问题：迁移、精度
  新增一个finding3，谈时间等等问题，把小图放进去
  
  现在的量化工作：专注于提升量化能力和量化质量
  我们的工作：提升code分配质量和表征的质量，保证高频信息的独特性和低频信息的训练，也就是说，code分配更均匀带来了特征交互中特征更能表示


理一理我们intro的逻辑：
  基础CTR提出
  深度学习CTR提出
  深度学习CTR要使用嵌入表
  嵌入表极大
  大嵌入表带来了大内存消耗
  大内存消耗带来了大时延

  为了解决这个问题，人们提出了内存高效嵌入
  分为哈希法和量化法

deep hash embedding
DHE, HydridHash, DoubleHash and QRTrick

Model-agnonic plug-and-switch compression method

A Model-Agnonic Plug-And-Play Compression Framework For CTR Prediction(MAPAP)
A Model-Unaware CTR Compression Framework(MUCF)
A Universal Plug-and-Compress Framework for CTR Prediction(UPluC)


### 20240812 推荐大模型技术报告
- 应该和tokenzier相关
- **LLM中的tokenizer，推荐中的tokenzizer（related work）**，以及“LLM帮助推荐的范式”详见文件夹中的图片（威哥部分）
  - 推荐，包括各种复杂技巧的related work
    - 推荐中的embedding：https://arxiv.org/pdf/2310.18608
  - 大模型，包括各种bert技巧
    - 语义ID？
    - 多层tokenzier？
    - 常规token？
    - 无监督tokenizer：https://arxiv.org/pdf/2307.07262v2 
    - 一篇大语言模型综述
- 技术报告到底有什么用呢？
  - 多行为大推荐模型到底有没有效？我们额外的实验对增加这个技术的信任度有帮助
  - 我们在做实验的时候，实际上对这个技术是有一定思考的，并且我们数据工程有很多实际结果
  - 第三个我们的效率角度的实验，已经做了一点了，可以当成工具书
- 一个小技术：是否未来都是纯时序的数据库呢？

### 20240826 下一步该干嘛？
- 扫会：Recsys24
- 读论文：
  - IDGenRec: LLM-RecSys Alignment with Textual ID Learning
- 总结一个关于tokenizer的ppt啥的

### 20240827 青创基金
- 表征部分目前我来写
- 研究基础：使用面上的论文，使用面上的研究基础进行改写成青创的写法
- （科学意义和创新性）挑战：参考面上，但是根据研究内容进行适配
- 研究内容2：标黄的是新加的，不标黄的是可以从面上里面抄的（基于大模型的跨域对齐，似乎应该是VQ-Rec那一套？）（括号里两点对应的是一个点的两个分点）
- 研究方案及技术路线：和研究内容对应一下，对着参考样例来写，要加技术词

### 20240829 青创基金修改
- 研究基础：
  - “针对xx问题”的时候，问题要提炼一些，短一些，并且问题一定要拐到主题上（提到表征）
  - 单个内容不能太长了
  - 几个点之间最好有点逻辑关系，不过我是从面上改过来的，所以应该不太要改
  - 再看一下有没有照着公式来写
- 挑战：
  - 好像套公式套的不太对，重新自查一下
- 研究内容
  - 公式套的不对，研究xx问题，提出xx方法，简介方法，达成什么效果
- 研究方案：
  - 标黄的意思是要照着这个写
  - 我要改后面的具体而言部分，先重点加粗，然后简单介绍一下，要明确分点
- 我那一块要强调分词器
- ddl：8.30十点

### 20240902 周一agent组会
- 现在可以针对amazon review生成对话式推荐的输入query了，
- seal，dsi相关的工作