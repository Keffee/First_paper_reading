mode: train

bert_path: /mnt/dolphinfs/hdd_pool/docker/user/hadoop-aipnlp/yangyang113/distillation_clean/plms/smallbert_yuji/auto-medium/

dataset: mt_intent_v2
train_dataset: 
  name: intent
  params:
    data_path: data/intent_v2/train.txt
train_data_collator:
  name: icgnn
  params:
    query_path: data/intent_v2/all_queries.txt
    graph_path: data/intent_v2/query_item_cate.graph
    fanouts: [10]
train_batch_size: 16


val_dataset: 
  name: intent
  params:
    data_path: data/intent_v2/val.txt
val_data_collator:
  name: icgnn
  params:
    query_path: data/intent_v2/all_queries.txt
    graph_path: data/intent_v2/query_item_cate.graph
    fanouts: [10]
valid_batch_size: 1024

test_dataset: 
  name: intent
  params:
    data_path: data/intent_v2/test.txt
test_data_collator:
  name: icgnn
  params:
    query_path: data/intent_v2/all_queries.txt
    graph_path: data/intent_v2/query_item_cate.graph
    fanouts: [10]
test_batch_size: 1024

model_params:
  graph: data/intent_v2/query_item_cate.graph
  h_dim: 384
  num_hidden_layers: 1
  dropout: 0
  use_self_loop: True
  num_classes: 386
  query_path: data/intent_v2/mt_bert_emb/query_emb.npy
  item_path: data/intent_v2/mt_bert_emb/item_emb.npy
  cate_path: data/intent_v2/mt_bert_emb/cate_emb.npy
  emb_freeze: False

# for dist
find_unused_parameters: False

#############
n_epoch: 1000
model: node_cls
early_stop: 4
max_length: 32
print_every: 50
save_every_epoch: 100
eval_every_epoch: 1
eval_func: eval_multi_class
main_metric: f1
random_seed: 666

optimizer: adam
optimizer_params:
  lr: 0.001



