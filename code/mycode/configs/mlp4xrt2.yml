mode: train

dataset: mt
train_data_path: data/mt/train
train_batch_size: 512
valid_data_path: data/mt/val
valid_batch_size: 1024
test_data_path: data/mt/test
test_batch_size: 1024
query_path: data/mt/queries
sup_path: data/mt/sups

model: mlp4xrt2
model_params:
  xrt_emb: data/mt/giant_xrt_emb.npy
  xrt_emb_grad: True
  dropout: 0.5


n_epoch: 1000
early_stop: 4
num_classes: 2
max_length: 32
print_every: 50
save_every_epoch: 5
eval_every_epoch: 1
main_metric: f1
random_seed: 666

optimizer: adam
optimizer_params:
  lr: 0.001

# scheduler_params:
#   scheduler: WarmupLinear
#   warmup_steps: 0.05


